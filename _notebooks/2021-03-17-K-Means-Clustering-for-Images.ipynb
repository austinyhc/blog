{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-03-17-K-Means-Clustering-for-Images.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwf+gS5gBXrAkPCr2KQHmW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JqrvCZoEY6s"
      },
      "source": [
        "# K-Means Clustering for Images\r\n",
        "> In this post, we will use a K-means algorithm to perform image classification. Clustering isn't limited to the consumer information and population sciences, it can be used for imagery analysis as well. Leveraging Scikit-learn and the MNIST dataset, we will investigate the use of K-means clustering for computer vision.\r\n",
        "\r\n",
        "- toc: true \r\n",
        "- badges: true\r\n",
        "- comments: true\r\n",
        "- author: Austin Chen\r\n",
        "- categories: [machine learning, vision]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuLBXeRjd8wU"
      },
      "source": [
        "## 1% Better Everyday\r\n",
        "- [K-Means Clustering for Imagery Analysis\r\n",
        "](https://goodboychan.github.io/python/machine_learning/natural_language_processing/vision/2020/10/26/01-K-Means-Clustering-for-Imagery-Analysis.html)\r\n",
        "- Debug why the accuray looks abnormal. Suspecting that something I did not add in the `get_label2cluster()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4bn0pNeE0Rz"
      },
      "source": [
        "%matplotlib inline\r\n",
        "\r\n",
        "import sys\r\n",
        "import sklearn\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSUbCCqfFuMZ"
      },
      "source": [
        "## Load Datasets\r\n",
        "\r\n",
        "To be quick, I will load the Fashion MNIST from TensorFlow Keras library, which is often used as the \"Hello World\" of machine learning programs for computer vision.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2XBqxEHHHLq",
        "outputId": "689a55a2-8c10-44b1-d4ce-0197df9d0eb5"
      },
      "source": [
        "#fashion_mnist = tf.keras.datasets.fashion_mnist\r\n",
        "#(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\r\n",
        "\r\n",
        "mnist = tf.keras.datasets.mnist\r\n",
        "(train_x, train_y), (test_x, test_y) = mnist.load_data()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNx5kE9nIjfC"
      },
      "source": [
        "CLASSES = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n",
        "NCLASSES = len(CLASSES)\r\n",
        "class2label = {i:c for i,c in enumerate(CLASSES)}"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnRmRTbUHsBZ",
        "outputId": "3a57c9cc-9ce2-423b-f507-dd7334130e82"
      },
      "source": [
        "print(f\"Training: {train_x.shape}\")\r\n",
        "print(f\"Test: {test_x.shape}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: (60000, 28, 28)\n",
            "Test: (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6sps2gQH5xj"
      },
      "source": [
        "AS you can see, the dataset contains images of 28x28x1. Let's print some out and see what they look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "pOqTPFjWHpyD",
        "outputId": "f244ac2b-c317-4c6e-a677-df63e16e67f3"
      },
      "source": [
        "fig,axs = plt.subplots(3,3,figsize=(12,12))\r\n",
        "plt.gray()\r\n",
        "\r\n",
        "for i,ax in enumerate(axs.flat):\r\n",
        "    ax.imshow(train_x[i])\r\n",
        "    ax.axis('off')\r\n",
        "    #ax.set_title(f'{class2label[train_y[i]]}')\r\n",
        "    ax.set_title(f'{train_y[i]}')"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cih1LhtVIdNv"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGjPVo8SJbzy"
      },
      "source": [
        "### Reshape\r\n",
        "\r\n",
        "Images are formated as 2-dimensional `numpy` arrays. However, the K-means clustering algorithm provided by scikit-learn ingests 1-dimensional arrays; as a result, we will need to reshape each image or precisely wee need to `flatten` the data. \r\n",
        "\r\n",
        "Clustering algorithms almost always use 1-dimensional data. For example, if you were clustering a set of X, Y coordinates, each point would be passed to the clustering algorithm as a 1-dimensional array with a length of two (example: [2,4] or [-1, 4]). If you were using 3-dimensional data, the array would have a length of 3 (example: [2, 4, 1] or [-1, 4, 5]).\r\n",
        "\r\n",
        "Fashion MNIST contains images that are 28 by 28 pixels; as a result, they will have a length of 784 once we reshape them into a 1-dimensional array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ0FrZJuJc4-"
      },
      "source": [
        "train_x = train_x.reshape(len(train_x), -1)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaCIVbPVMjhu",
        "outputId": "f6edc015-f115-4ec7-f787-0b5016bbb618"
      },
      "source": [
        "print(train_x.shape)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wMpvOmsMtq6"
      },
      "source": [
        "train_x = train_x.astype(np.float32) / 255.0"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5F2WP8_MyWt"
      },
      "source": [
        "## Applying K-means Clustering\r\n",
        "Since the size of the MNIST dataset is quite large, we will use the **mini-batch** implementation of k-means clustering (`MiniBatchKMeans`) provided by scikit-learn. This will dramatically reduce the amount of time it takes to fit the algorithm to the data.\r\n",
        "\r\n",
        "Here, we just choose the `n_clusters` argument to the `n_digits`(the size of unique labels, in our case, 10), and set the default parameters in `MiniBatchKMeans`.\r\n",
        "\r\n",
        "And as you know that, K-means clustering is one of the unsupervised learning. That means it doesn't require any label to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBaLAjShNCiJ"
      },
      "source": [
        "from sklearn.cluster import MiniBatchKMeans"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omg_SKcFNLJQ",
        "outputId": "5f4768fa-80dc-4203-a355-bf0c6e12040a"
      },
      "source": [
        "kmeans = MiniBatchKMeans(n_clusters=NCLASSES)\r\n",
        "kmeans.fit(train_x)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
              "                init_size=None, max_iter=100, max_no_improvement=10,\n",
              "                n_clusters=10, n_init=3, random_state=None,\n",
              "                reassignment_ratio=0.01, tol=0.0, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUJtlgu0NyHN",
        "outputId": "5b619438-af3a-4b71-c0bd-bac9526d9a2b"
      },
      "source": [
        "kmeans.labels_"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 0, ..., 7, 1, 7], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA006al6SPXW",
        "outputId": "0f4f5ce1-f3c9-43be-b32e-5bc37d702d61"
      },
      "source": [
        "NCLASSES"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4N85K3FOUBQ"
      },
      "source": [
        "> Important: These are not real label of each image. These are just group ids that the clustering models label for each input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_07QWYJiOue1"
      },
      "source": [
        "To match group ids with actual labels, we can tackle this with following steps:\r\n",
        "- Combine each images in the same group\r\n",
        "- Check frequency distribution of actual labels (using `np.bincount`)\r\n",
        "- Find the most frequent label by `np.argmax` and set the label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5G5sJbISers"
      },
      "source": [
        "def get_label2cluster_mapper(kmeans, ground_trues):\r\n",
        "\r\n",
        "    label2cluster= {}\r\n",
        "\r\n",
        "    for i in range(kmeans.n_clusters):\r\n",
        "        indeces = np.where(kmeans.labels_ == i)\r\n",
        "        labels = ground_trues[indeces]\r\n",
        "\r\n",
        "        hist = (np.bincount(np.squeeze(labels)))\r\n",
        "\r\n",
        "        if np.argmax(hist) in label2cluster:\r\n",
        "            label2cluster[np.argmax(hist)].append(i)\r\n",
        "        else:\r\n",
        "            label2cluster[np.argmax(hist)] = [i]\r\n",
        "\r\n",
        "    return label2cluster"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IIy5i-aWgSX"
      },
      "source": [
        "def convert_cluster_to_label(clusters, mapper):\r\n",
        "    preds = np.zeros(len(clusters)).astype(np.uint8)\r\n",
        "    for i,cl in enumerate(clusters):\r\n",
        "        for k,v in mapper.items():\r\n",
        "            if cl in v: preds[i] = k\r\n",
        "    return preds"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQHiwBntV5kB",
        "outputId": "71c3568c-2675-476c-cb01-469eca545364"
      },
      "source": [
        "label2cluster = get_label2cluster_mapper(kmeans, train_y)\r\n",
        "train_cl = kmeans.predict(train_x)\r\n",
        "preds = convert_cluster_to_label(train_cl, label2cluster)\r\n",
        "print(preds[:20])\r\n",
        "print(train_y[:20])"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8 0 4 1 7 8 1 8 1 7 3 1 3 6 1 7 2 8 6 1]\n",
            "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YduasIES0ih",
        "outputId": "e4777579-e7f6-45c0-d8be-4030560c7d47"
      },
      "source": [
        "print(f\"Accuracy : {sum(preds == train_y)/len(preds) * 100}%\")"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 56.015%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWb0fry1RcKV"
      },
      "source": [
        "As a result, some predicted label is mismatched, but in general k-means clustering does an acceptable jobs of predicting labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "455o_-4QSLSf"
      },
      "source": [
        "## Evaluating Clustering \r\n",
        "\r\n",
        "With the functions defined above, we can now determine the accuracy of our algorithms. Since we are using this clustering algorithm for classification, accuracy is ultimately the most important metric; however, there are other metrics out there that can be applied directly to the clusters themselves, regardless of the associated labels. Two of these metrics that we will use are **inertia** and **homogeneity**. (See the detailed description of [homogeneity_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_score.html))\r\n",
        "\r\n",
        "Furthermore, earlier we made the assumption that K = 10 was the appropriate number of clusters; however, this might not be the case. Let's fit the K-means clustering algorithm with several different values of K, than evaluate the performance using our metrics.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFtYC7ZJcTFL"
      },
      "source": [
        "from sklearn.metrics import homogeneity_score\r\n",
        "\r\n",
        "def calc_metrics(estimator, data, labels):\r\n",
        "    print('Number of Clusters: {}'.format(estimator.n_clusters))\r\n",
        "    # Inertia\r\n",
        "    inertia = estimator.inertia_\r\n",
        "    print(\"Inertia: {}\".format(inertia))\r\n",
        "    # Homogeneity Score\r\n",
        "    homogeneity = homogeneity_score(labels, estimator.labels_)\r\n",
        "    print(\"Homogeneity score: {}\".format(homogeneity))\r\n",
        "    return inertia, homogeneity"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzWEXVrTcbhE",
        "outputId": "517b6a76-1b24-4ffd-abcc-2f685926f2e3"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "clusters = [10, 16, 36, 64, 144, 256]\r\n",
        "iner_list = []\r\n",
        "homo_list = []\r\n",
        "acc_list = []\r\n",
        "\r\n",
        "for n_clusters in clusters:\r\n",
        "    estimator = MiniBatchKMeans(n_clusters=n_clusters)\r\n",
        "    estimator.fit(train_x)\r\n",
        "    \r\n",
        "    inertia, homo = calc_metrics(estimator, train_x, train_y)\r\n",
        "    iner_list.append(inertia)\r\n",
        "    homo_list.append(homo)\r\n",
        "    \r\n",
        "    # Determine predicted labels\r\n",
        "    labels2cluster = get_label2cluster_mapper(estimator, train_y)\r\n",
        "    preds = convert_cluster_to_label(estimator.labels_, label2cluster)\r\n",
        "    \r\n",
        "    acc = accuracy_score(train_y, preds)\r\n",
        "    acc_list.append(acc)\r\n",
        "    print('Accuracy: {}\\n'.format(acc))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Clusters: 10\n",
            "Inertia: 2374295.5\n",
            "Homogeneity score: 0.47531735445630136\n",
            "Accuracy: 0.058133333333333335\n",
            "\n",
            "Number of Clusters: 16\n",
            "Inertia: 2233699.5\n",
            "Homogeneity score: 0.5342048472152641\n",
            "Accuracy: 0.13905\n",
            "\n",
            "Number of Clusters: 36\n",
            "Inertia: 1958344.25\n",
            "Homogeneity score: 0.6801597667242121\n",
            "Accuracy: 0.1241\n",
            "\n",
            "Number of Clusters: 64\n",
            "Inertia: 1816912.875\n",
            "Homogeneity score: 0.7365330512499944\n",
            "Accuracy: 0.10248333333333333\n",
            "\n",
            "Number of Clusters: 144\n",
            "Inertia: 1633745.875\n",
            "Homogeneity score: 0.7982088109533748\n",
            "Accuracy: 0.10348333333333333\n",
            "\n",
            "Number of Clusters: 256\n",
            "Inertia: 1517294.5\n",
            "Homogeneity score: 0.8384997758424939\n",
            "Accuracy: 0.095\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}