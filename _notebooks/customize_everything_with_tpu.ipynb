{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "customize-everything-with-tpu.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx1_IgRWYjl3"
      },
      "source": [
        "# Custom Everything with TPU\n",
        "> Getting start to customize everything with TPU\n",
        "\n",
        "- toc: true\n",
        "- badges: true\n",
        "- author: Austin Chen\n",
        "- categories: [plant,classification,tpu,custom]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGOP16xrR0xM"
      },
      "source": [
        "# 1% Better Everyday\r\n",
        "- Add momentum to the custom optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeVXTsmCI2gz",
        "outputId": "5a24bbc6-b78d-4932-d24a-ab08f1357f43"
      },
      "source": [
        "#hide\n",
        "\n",
        "%%writefile conditional_cell_extension.py\n",
        "def run_if(line, cell=None):\n",
        "    '''Execute current line/cell if line evaluates to True.'''\n",
        "    if not eval(line):\n",
        "        return\n",
        "    get_ipython().ex(cell)\n",
        "\n",
        "def load_ipython_extension(shell):\n",
        "    '''Registers the run_if magic when the extension loads.'''\n",
        "    shell.register_magic_function(run_if, 'line_cell')\n",
        "\n",
        "def unload_ipython_extension(shell):\n",
        "    '''Unregisters the run_if magic when the extension unloads.'''\n",
        "    del shell.magics_manager.magics['cell']['run_if']"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting conditional_cell_extension.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmMCwqzIYOtg"
      },
      "source": [
        "#hide\n",
        "%reload_ext conditional_cell_extension"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otni27YClmXy",
        "outputId": "b29317d1-3125-4bb9-ede9-c9bb0237851d"
      },
      "source": [
        "#collapse-hide\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "import os, gc, cv2, random, re, datetime\n",
        "import warnings, math, sys, json\n",
        "import subprocess, pprint, pdb\n",
        "from functools import partial\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "from fastprogress.fastprogress import master_bar, progress_bar\n",
        "\n",
        "warnings.simplefilter('ignore')\n",
        "print(f\"Using TensorFlow v{tf.__version__}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow v2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdGk_Jxx4llz",
        "cellView": "form",
        "outputId": "624a3bf1-f341-4a33-ca2b-8006086ec82d"
      },
      "source": [
        "#hide\n",
        "#@title Accelerator { run: \"auto\" }\n",
        "DEVICE = 'TPU' #@param [\"None\", \"'GPU'\", \"'TPU'\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "if DEVICE == \"TPU\":\n",
        "    print(\"connecting to TPU...\")\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        print('Running on TPU ', tpu.master())\n",
        "    except ValueError:\n",
        "        print(\"Could not connect to TPU\")\n",
        "        tpu = None\n",
        "\n",
        "    if tpu:\n",
        "        try:\n",
        "            print(\"initializing  TPU ...\")\n",
        "            tf.config.experimental_connect_to_cluster(tpu)\n",
        "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "            print(\"TPU initialized\")\n",
        "        except _:\n",
        "            print(\"failed to initialize TPU\")\n",
        "    else:\n",
        "        DEVICE = \"GPU\"\n",
        "\n",
        "if DEVICE != \"TPU\":\n",
        "    print(\"Using default strategy for CPU and single GPU\")\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "if DEVICE == \"GPU\":\n",
        "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "    \n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(f'REPLICAS: {REPLICAS}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "connecting to TPU...\n",
            "Running on TPU  grpc://10.98.250.98:8470\n",
            "initializing  TPU ...\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.98.250.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.98.250.98:8470\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHnmp3zCv2Qd"
      },
      "source": [
        "> Tip: Adding seed helps reproduce results. Setting debug parameter wil run the model on smaller number of epochs to validate the architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwq8rme7ybKg"
      },
      "source": [
        "#collapse-hide\n",
        "def seed_everything(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "GOOGLE = 'google.colab' in str(get_ipython())\n",
        "KAGGLE = not GOOGLE\n",
        "\n",
        "print(\"Running on {}!\".format(\n",
        "   \"Google Colab\" if GOOGLE else \"Kaggle Kernel\"\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOKZOBChvYjC"
      },
      "source": [
        "#hide\n",
        "#@title ML Lifecycle { run: \"auto\", display-mode: \"form\" }\n",
        "SEED = 16\n",
        "DEBUG = False #@param {type:\"boolean\"}\n",
        "TRAIN = True #@param {type:\"boolean\"}\n",
        "\n",
        "seed_everything(SEED)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ_JPA_dZSn6"
      },
      "source": [
        "#hide\n",
        "#%%run_if {GOOGLE}\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUeHshgckTuA"
      },
      "source": [
        "#hide\n",
        "project_name = 'tpu-getting-started'\n",
        "root_path  = '/content/gdrive/MyDrive/' if GOOGLE else '/'\n",
        "input_path = f'{root_path}kaggle/input/{project_name}/'\n",
        "working_path = f'{input_path}working/' if GOOGLE else '/kaggle/working/'\n",
        "os.makedirs(working_path, exist_ok=True)\n",
        "os.chdir(working_path)\n",
        "os.listdir(input_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMyqn7VJpvEj"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wgUMYjypzIl"
      },
      "source": [
        "#@title {run: \"auto\", display-mode: \"form\" }\n",
        "\n",
        "HEIGHT = 512#@param {type:\"number\"}\n",
        "WIDTH = 512#@param {type:\"number\"}\n",
        "CHANNELS = 3#@param {type:\"number\"}\n",
        "IMG_SIZE = (HEIGHT, WIDTH, CHANNELS)\n",
        "EPOCHS =  50#@param {type:\"number\"}\n",
        "BATCH_SIZE = 32 * strategy.num_replicas_in_sync #@param {type:\"raw\"}\n",
        "\n",
        "print(\"Input size: {}\".format(IMG_SIZE))\n",
        "print(\"Train on batch size of {} for {} epochs\".format(BATCH_SIZE, EPOCHS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys-E40LpDypm"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2O6Ep2-rDj8"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl5ee0MSVw-p"
      },
      "source": [
        "#hide\n",
        "%%run_if {KAGGLE}\n",
        "from kaggle_datasets import KaggleDatasets\n",
        "GCS_DS_PATH = KaggleDatasets().get_gcs_path(project_name)\n",
        "GCS_PATH_SELECT = {\n",
        "    192: GCS_DS_PATH + '/tfrecords-jpeg-192x192',\n",
        "    224: GCS_DS_PATH + '/tfrecords-jpeg-224x224',\n",
        "    331: GCS_DS_PATH + '/tfrecords-jpeg-331x331',\n",
        "    512: GCS_DS_PATH + '/tfrecords-jpeg-512x512'\n",
        "}\n",
        "print(f\"Sourcing images from\")\n",
        "for v in GCS_PATH_SELECT.values(): print(f\"\\t{v}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XeAHlwaRn0m",
        "cellView": "form"
      },
      "source": [
        "%%run_if {GOOGLE}\n",
        "#@title {run: \"auto\", display-mode: \"form\"}\n",
        "# reference: https://www.kaggle.com/austinyhc/custom-training-with-tpu?scriptVersionId=51687595\n",
        "GCS_DS_PATH = 'gs://kds-7396cd0f7b0e4a357b814bc6e35f76021f3a9f220e13e7b2d3c3fb39' #@param {type: \"string\"}\n",
        "GCS_PATH_SELECT = {\n",
        "    192: GCS_DS_PATH + '/tfrecords-jpeg-192x192',\n",
        "    224: GCS_DS_PATH + '/tfrecords-jpeg-224x224',\n",
        "    331: GCS_DS_PATH + '/tfrecords-jpeg-331x331',\n",
        "    512: GCS_DS_PATH + '/tfrecords-jpeg-512x512'\n",
        "}\n",
        "print(f\"Sourcing images from\")\n",
        "for v in GCS_PATH_SELECT.values(): print(f\"\\t{v}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeTYivWhWVG9"
      },
      "source": [
        "#collapse-hide\n",
        "CLASSES = ['pink primrose',        'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',\n",
        "           'tiger lily',           'moon orchid',               'bird of paradise', 'monkshood',     'globe thistle',        \n",
        "           'snapdragon',           \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',\n",
        "           'globe-flower',         'purple coneflower',         'peruvian lily',    'balloon flower','giant white arum lily',\n",
        "           'fire lily',            'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',\n",
        "           'corn poppy',           'prince of wales feathers',  'stemless gentian', 'artichoke',     'sweet william',        \n",
        "           'carnation',            'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',\n",
        "           'ruby-lipped cattleya', 'cape flower',               'great masterwort', 'siam tulip',    'lenten rose',          \n",
        "           'barberton daisy',      'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',\n",
        "           'wallflower',           'marigold',                  'buttercup',        'daisy',         'common dandelion',     \n",
        "           'petunia',              'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',\n",
        "           'bishop of llandaff',   'gaura',                     'geranium',         'orange dahlia', 'pink-yellow dahlia',   \n",
        "           'cautleya spicata',     'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy',\n",
        "           'osteospermum',         'spring crocus',             'iris',             'windflower',    'tree poppy',           \n",
        "           'gazania',              'azalea',                    'water lily',       'rose',          'thorn apple',\n",
        "           'morning glory',        'passion flower',            'lotus',            'toad lily',     'anthurium',\n",
        "           'frangipani',           'clematis',                  'hibiscus',         'columbine',     'desert-rose',\n",
        "           'tree mallow',          'magnolia',                  'cyclamen ',        'watercress',    'canna lily',           \n",
        "           'hippeastrum ',         'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',\n",
        "           'camellia',             'mallow',                    'mexican petunia',  'bromelia',      'blanket flower',       \n",
        "           'trumpet creeper',      'blackberry lily',           'common tulip',     'wild rose']\n",
        "\n",
        "with strategy.scope():\n",
        "    NCLASSES = len(CLASSES)\n",
        "print(f\"Number of labels: {NCLASSES}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDGZ1hJ0TRge"
      },
      "source": [
        "def count_data_items(filenames):\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1))\n",
        "            for filename in filenames]\n",
        "    return np.sum(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPpNJSt9crkU"
      },
      "source": [
        "def inspect_tfrecord(tfrec):\r\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrec)\r\n",
        "    for raw_record in raw_dataset.take(1):\r\n",
        "        example = tf.train.Example()\r\n",
        "        example.ParseFromString(raw_record.numpy())\r\n",
        "    print(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIj5h2KIR8oU"
      },
      "source": [
        "train_filenames = tf.io.gfile.glob(GCS_PATH_SELECT[HEIGHT] + '/train/*.tfrec')\n",
        "valid_filenames = tf.io.gfile.glob(GCS_PATH_SELECT[HEIGHT] + '/val/*.tfrec')\n",
        "test_filenames  = tf.io.gfile.glob(GCS_PATH_SELECT[HEIGHT] + '/test/*.tfrec') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-j2Iub6Ulg2"
      },
      "source": [
        "#hide-input\n",
        "print(\"Number of train set: {}\\n\"\n",
        "      \"Number of valid set: {}\\n\"\n",
        "      \"Number of test set:  {}\\n\"\n",
        "      .format(count_data_items(train_filenames),\n",
        "              count_data_items(valid_filenames),\n",
        "              count_data_items(test_filenames)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4c0-lvnfdf-"
      },
      "source": [
        "inspect_tfrecord(train_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8XVcC_GfleG"
      },
      "source": [
        "def decode_image(image_string):\r\n",
        "    image = tf.image.decode_jpeg(image_string, channels=3)\r\n",
        "    image = tf.cast(image, tf.float32) / 255.0\r\n",
        "    image = tf.reshape(image, IMG_SIZE)\r\n",
        "    return image\r\n",
        "\r\n",
        "def read_tfrecord(example, labeled=True):\r\n",
        "    TFREC_FORMAT = {\r\n",
        "        \"image\" : tf.io.FixedLenFeature([],tf.string),\r\n",
        "        \"class\" : tf.io.FixedLenFeature([],tf.int64),\r\n",
        "        \"id\"    : tf.io.FixedLenFeature([],tf.string),\r\n",
        "    } if labeled else {\r\n",
        "        \"image\" : tf.io.FixedLenFeature([],tf.string),\r\n",
        "        \"id\"    : tf.io.FixedLenFeature([],tf.string),\r\n",
        "    }\r\n",
        "    example = tf.io.parse_single_example(example, TFREC_FORMAT)\r\n",
        "    image = decode_image(example['image'])\r\n",
        "    label = tf.cast(example['class'], tf.int32) if labeled else example['id']\r\n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtE3n6p6rJL3"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03N3xU5XKs1a"
      },
      "source": [
        "#collapse-hide\n",
        "def transform_shear(image, height, shear):\n",
        "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
        "    # output - image randomly sheared\n",
        "    DIM = height\n",
        "    XDIM = DIM%2 #fix for size 331\n",
        "    \n",
        "    shear = shear * tf.random.uniform([1],dtype='float32')\n",
        "    shear = math.pi * shear / 180.\n",
        "        \n",
        "    # SHEAR MATRIX\n",
        "    one = tf.constant([1],dtype='float32')\n",
        "    zero = tf.constant([0],dtype='float32')\n",
        "    c2 = tf.math.cos(shear)\n",
        "    s2 = tf.math.sin(shear)\n",
        "    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n",
        "\n",
        "    # LIST DESTINATION PIXEL INDICES\n",
        "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
        "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
        "    z = tf.ones([DIM*DIM],dtype='int32')\n",
        "    idx = tf.stack( [x,y,z] )\n",
        "    \n",
        "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
        "    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n",
        "    idx2 = K.cast(idx2,dtype='int32')\n",
        "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
        "    \n",
        "    # FIND ORIGIN PIXEL VALUES \n",
        "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
        "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
        "        \n",
        "    return tf.reshape(d,[DIM,DIM,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgGAtFpcgvBm"
      },
      "source": [
        "#collapse-hide\n",
        "def transform_shift(image, height, h_shift, w_shift):\n",
        "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
        "    # output - image randomly shifted\n",
        "    DIM = height\n",
        "    XDIM = DIM%2 #fix for size 331\n",
        "    \n",
        "    height_shift = h_shift * tf.random.uniform([1],dtype='float32') \n",
        "    width_shift = w_shift * tf.random.uniform([1],dtype='float32') \n",
        "    one = tf.constant([1],dtype='float32')\n",
        "    zero = tf.constant([0],dtype='float32')\n",
        "        \n",
        "    # SHIFT MATRIX\n",
        "    shift_matrix = tf.reshape(tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3])\n",
        "\n",
        "    # LIST DESTINATION PIXEL INDICES\n",
        "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
        "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
        "    z = tf.ones([DIM*DIM],dtype='int32')\n",
        "    idx = tf.stack( [x,y,z] )\n",
        "    \n",
        "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
        "    idx2 = K.dot(shift_matrix,tf.cast(idx,dtype='float32'))\n",
        "    idx2 = K.cast(idx2,dtype='int32')\n",
        "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
        "    \n",
        "    # FIND ORIGIN PIXEL VALUES \n",
        "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
        "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
        "        \n",
        "    return tf.reshape(d,[DIM,DIM,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIzqWAi4ZOW_"
      },
      "source": [
        "#collapse-hide\n",
        "def transform_rotation(image, height, rotation):\n",
        "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
        "    # output - image randomly rotated\n",
        "    DIM = height\n",
        "    XDIM = DIM%2 #fix for size 331\n",
        "    \n",
        "    rotation = rotation * tf.random.uniform([1],dtype='float32')\n",
        "    # CONVERT DEGREES TO RADIANS\n",
        "    rotation = math.pi * rotation / 180.\n",
        "    \n",
        "    # ROTATION MATRIX\n",
        "    c1 = tf.math.cos(rotation)\n",
        "    s1 = tf.math.sin(rotation)\n",
        "    one = tf.constant([1],dtype='float32')\n",
        "    zero = tf.constant([0],dtype='float32')\n",
        "    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n",
        "\n",
        "    # LIST DESTINATION PIXEL INDICES\n",
        "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
        "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
        "    z = tf.ones([DIM*DIM],dtype='int32')\n",
        "    idx = tf.stack( [x,y,z] )\n",
        "    \n",
        "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
        "    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n",
        "    idx2 = K.cast(idx2,dtype='int32')\n",
        "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
        "    \n",
        "    # FIND ORIGIN PIXEL VALUES \n",
        "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
        "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
        "        \n",
        "    return tf.reshape(d,[DIM,DIM,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvShvzIWvsyY"
      },
      "source": [
        "#collapse-show\n",
        "def data_augment(image, label):\n",
        "    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel = tf.random.uniform([], 0, 1.0, dtype=tf.float32)    \n",
        "    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_shift = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    \n",
        "    # Flips\n",
        "    if p_spatial >= .2:\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "        image = tf.image.random_flip_up_down(image)\n",
        "        \n",
        "    # Rotates\n",
        "    if p_rotate > .75:\n",
        "        image = tf.image.rot90(image, k=3) # rotate 270º\n",
        "    elif p_rotate > .5:\n",
        "        image = tf.image.rot90(image, k=2) # rotate 180º\n",
        "    elif p_rotate > .25:\n",
        "        image = tf.image.rot90(image, k=1) # rotate 90º\n",
        "    \n",
        "    if p_rotation >= .3: # Rotation\n",
        "        image = transform_rotation(image, height=HEIGHT, rotation=45.)\n",
        "    if p_shift >= .3: # Shift\n",
        "        image = transform_shift(image, height=HEIGHT, h_shift=15., w_shift=15.)\n",
        "    if p_shear >= .3: # Shear\n",
        "        image = transform_shear(image, height=HEIGHT, shear=20.)\n",
        "        \n",
        "    # Crops\n",
        "    if p_crop > .4:\n",
        "        crop_size = tf.random.uniform([], int(HEIGHT*.7), HEIGHT, dtype=tf.int32)\n",
        "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n",
        "    elif p_crop > .7:\n",
        "        if p_crop > .9:\n",
        "            image = tf.image.central_crop(image, central_fraction=.7)\n",
        "        elif p_crop > .8:\n",
        "            image = tf.image.central_crop(image, central_fraction=.8)\n",
        "        else:\n",
        "            image = tf.image.central_crop(image, central_fraction=.9)\n",
        "            \n",
        "    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n",
        "        \n",
        "    # Pixel-level transforms\n",
        "    if p_pixel >= .2:\n",
        "        if p_pixel >= .8:\n",
        "            image = tf.image.random_saturation(image, lower=0, upper=2)\n",
        "        elif p_pixel >= .6:\n",
        "            image = tf.image.random_contrast(image, lower=.8, upper=2)\n",
        "        elif p_pixel >= .4:\n",
        "            image = tf.image.random_brightness(image, max_delta=.2)\n",
        "        else:\n",
        "            image = tf.image.adjust_gamma(image, gamma=.6)\n",
        "\n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hppHn7b7jioz"
      },
      "source": [
        "def load_dataset(filenames, labeled=True, ordered=False):\r\n",
        "    ignore_order = tf.data.Options()\r\n",
        "    if not ordered: ignore_order.experimental_deterministic = False\r\n",
        "    ds = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\r\n",
        "    ds = ds.with_options(ignore_order)\r\n",
        "    ds = ds.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\r\n",
        "    return ds\r\n",
        "\r\n",
        "def get_train_dataset(filenames):\r\n",
        "    ds = load_dataset(filenames, labeled=True)\r\n",
        "    ds = ds.map(data_augment, num_parallel_calls=AUTOTUNE)\r\n",
        "    ds = ds.shuffle(2048)\r\n",
        "    ds = ds.batch(BATCH_SIZE)\r\n",
        "    # prefetch the next batch while training\r\n",
        "    ds = ds.prefetch(AUTOTUNE)\r\n",
        "    return ds\r\n",
        " \r\n",
        "def get_valid_dataset(filenames, ordered=False):\r\n",
        "    ds = load_dataset(filenames, labeled=True, ordered=ordered)\r\n",
        "    ds = ds.batch(BATCH_SIZE)\r\n",
        "    ds= ds.cache()\r\n",
        "    # prefetch the next batch while training\r\n",
        "    ds = ds.prefetch(AUTOTUNE)\r\n",
        "    return ds\r\n",
        "\r\n",
        "def get_test_dataset(filenames, ordered=False): \r\n",
        "    ds = load_dataset(filenames, labeled=False, ordered=ordered)\r\n",
        "    ds = ds.batch(BATCH_SIZE)\r\n",
        "    # prefetch the next batch while training\r\n",
        "    ds = ds.prefetch(AUTOTUNE)\r\n",
        "    return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRIpfK61lZOU"
      },
      "source": [
        "train_ds = get_train_dataset(train_filenames)\r\n",
        "valid_ds = get_valid_dataset(valid_filenames)\r\n",
        "test_ds  = get_test_dataset(test_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mlrrds8e2YV"
      },
      "source": [
        "#collapse-show\r\n",
        "def show_images(ds):\r\n",
        "    _,axs = plt.subplots(3,3,figsize=(16,16))\r\n",
        "    for ((x, y), ax) in zip(ds.take(9), axs.flatten()):\r\n",
        "        ax.imshow((x.numpy()*255).astype(np.uint8))\r\n",
        "        ax.set_title(CLASSES[y])\r\n",
        "        ax.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE3eMLYTa0xq"
      },
      "source": [
        "#hide\n",
        "show_images(train_ds.take(1).unbatch())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SUMa3ZXdVz1"
      },
      "source": [
        "#hide\n",
        "show_images(valid_ds.take(1).unbatch())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6WKtOmJrOEg"
      },
      "source": [
        "# Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOTMaCIVto_g"
      },
      "source": [
        "from tensorflow.keras.applications import Xception\r\n",
        "from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201\r\n",
        "from tensorflow.keras.applications import ResNet50V2, ResNet101V2, ResNet152V2\r\n",
        "from tensorflow.keras.applications import InceptionV3\r\n",
        "from tensorflow.keras.applications import InceptionResNetV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpi4un74prQN"
      },
      "source": [
        "class Flower_Classifier(tf.keras.models.Model):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.image_embedding_layers = []\r\n",
        "        self.image_embedding_layers.append(\r\n",
        "            Xception(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=IMG_SIZE))\r\n",
        "        self.image_embedding_layers.append(\r\n",
        "            ResNet152V2(weights='imagenet',\r\n",
        "                        include_top=False,\r\n",
        "                        input_shape=IMG_SIZE))\r\n",
        "        self.image_embedding_layers.append(\r\n",
        "            InceptionResNetV2(weights='imagenet',\r\n",
        "                              include_top=False,\r\n",
        "                              input_shape=IMG_SIZE))\r\n",
        "        self.pooling_layer = tf.keras.layers.GlobalAveragePooling2D()\r\n",
        "\r\n",
        "        self.layer_normalization_layers = []\r\n",
        "        self.prob_dist_layers = []\r\n",
        "        for model_idx, image_embedded_layer in enumerate(self.image_embedding_layers):\r\n",
        "            self.layer_normalization_layers.append(\r\n",
        "                tf.keras.layers.LayerNormalization(epsilon=1E-6))\r\n",
        "            self.prob_dist_layers.append(\r\n",
        "                tf.keras.layers.Dense(NCLASSES, activation='softmax',\r\n",
        "                                      name=f'prob_dist_{model_idx}'))\r\n",
        "\r\n",
        "        kernel_init = tf.constant_initializer(\r\n",
        "            np.array([0.86690587, 1.0948032, 1.1121726])) \r\n",
        "        bias_init = tf.constant_initializer(\r\n",
        "            np.array([-0.13309559, 0.09480964, 0.11218266]))\r\n",
        "\r\n",
        "        self.prob_dist_weight = tf.keras.layers.Dense(\r\n",
        "            len(self.image_embedding_layers), activation=\"softmax\",\r\n",
        "            kernel_initializer=kernel_init,\r\n",
        "            bias_initializer=bias_init,\r\n",
        "            name='prob_dist_weight')\r\n",
        "\r\n",
        "    def call(self, inputs, training=False):\r\n",
        "        all_model_outputs=[]\r\n",
        "        for i in range(len(self.image_embedding_layers)):\r\n",
        "            embedding = self.image_embedding_layers[i](inputs, training=training)\r\n",
        "            pooling = self.pooling_layer(embedding, training=training)\r\n",
        "            pooling_normalized = self.layer_normalization_layers[i](pooling, training=training)\r\n",
        "            model_output = self.prob_dist_layers[i](pooling_normalized, training=training)\r\n",
        "            all_model_outputs.append(model_output)\r\n",
        "\r\n",
        "        all_model_outputs = tf.stack(all_model_outputs, axis=1)\r\n",
        "        prob_dist_weight = self.prob_dist_weight(tf.constant(1, shape=(1,1)), training=training)\r\n",
        "        prob_dist = tf.linalg.matmul(prob_dist_weight, all_model_outputs)\r\n",
        "        prob_dist = prob_dist[:, 0, :]\r\n",
        "        return prob_dist\r\n",
        "\r\n",
        "    def model(self):\r\n",
        "        x = tf.keras.Input(shape=IMG_SIZE)\r\n",
        "        return tf.keras.Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZJFtyu2tXhB"
      },
      "source": [
        "with strategy.scope(): flower_classifier = Flower_Classifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC43XKNkm-aV"
      },
      "source": [
        "> Note: There is a workaround to show `summary()` of a subclassing model which is introduced in [this video](https://youtu.be/WcZ_1IAH_nM?list=PLhhyoLH6IjfxVOdVC1P1L5z5azs0XjMsb&t=1124)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKXqWqzlwKfe"
      },
      "source": [
        "flower_classifier.model().summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSdufYiewdBU"
      },
      "source": [
        "# Custom Optimizer Schedule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTsCqIGPxFNZ"
      },
      "source": [
        "class CustomCyclicSchedule(tf.keras.experimental.CosineDecay):\r\n",
        "    def __init__(self, n_step, lr_max, div=25.0, div_final=1e5,\r\n",
        "                 pct_start=0.25, staircase=False, cycle=False, name=None):\r\n",
        "        self.lr_start = lr_max / div\r\n",
        "        self.lr_min = lr_max / div_final\r\n",
        "        self.rising_steps = int(n_step * pct_start)\r\n",
        "        self.rising_a = (lr_max-self.lr_min) / (self.rising_steps-1)\r\n",
        "        self.rising_b = self.lr_min\r\n",
        "\r\n",
        "        self.falling_steps = int(n_step - self.rising_steps)\r\n",
        "        self.falling_rate = self.lr_min / lr_max\r\n",
        "        self.cycle = tf.constant(cycle, dtype=tf.bool)\r\n",
        "\r\n",
        "        super().__init__(\r\n",
        "            initial_learning_rate = lr_max,\r\n",
        "            decay_steps = self.falling_steps,\r\n",
        "            alpha=self.lr_min,\r\n",
        "            name = name)\r\n",
        "\r\n",
        "\r\n",
        "    def __call__(self, step):\r\n",
        "        \"\"\" `step` is actually the step index, starting at 0. \"\"\"\r\n",
        "        lr = (self.rising_a*tf.cast(step, tf.float32) + self.rising_b\r\n",
        "                if step < self.rising_steps else\r\n",
        "              super().__call__(tf.cast(step-self.rising_steps, tf.int32)))\r\n",
        "        return tf.cast(lr, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VihKrQZwzrd"
      },
      "source": [
        "#@title One-Cycle Scheduler {display-mode: \"form\", run: \"auto\"}\r\n",
        "with strategy.scope():\r\n",
        "    NSTEPS = math.ceil(count_data_items(train_filenames) / BATCH_SIZE) * EPOCHS\r\n",
        "    LR_MAX = 1e-4 #@param {type: \"number\"}\r\n",
        "    LR_MAX *= strategy.num_replicas_in_sync\r\n",
        "    DIV = 25.0 #@param {type: \"number\"}\r\n",
        "    DIV_FINAL = 1e5 #@param {type: \"number\"}\r\n",
        "    PCT_START = 0.25#@param {type: \"number\"}\r\n",
        "    \r\n",
        "    schedule = CustomCyclicSchedule(\r\n",
        "        n_step=NSTEPS,\r\n",
        "        lr_max=LR_MAX,\r\n",
        "        div=DIV,\r\n",
        "        div_final=DIV_FINAL,\r\n",
        "        cycle=False,\r\n",
        "        name=None)\r\n",
        "\r\n",
        "xps = tf.range(NSTEPS)\r\n",
        "yps = [schedule(x) for x in xps]\r\n",
        "fig,ax = plt.subplots(1,1,figsize=(8,5),facecolor='#F0F0F0')\r\n",
        "ax.plot(xps, yps)\r\n",
        "ax.set_facecolor('#F8F8F8')\r\n",
        "ax.set_xlabel('iteration')\r\n",
        "ax.set_ylabel('learning rate')\r\n",
        "\r\n",
        "print('{:d} total epochs and {:d} steps per epoch'\r\n",
        "        .format(EPOCHS, NSTEPS // EPOCHS))\r\n",
        "print(schedule.get_config())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9gbGC6GMbED"
      },
      "source": [
        "with strategy.scope():\r\n",
        "    opt = tf.keras.optimizers.Adam(schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRg2eMv-bCtQ"
      },
      "source": [
        "## Custom Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsY_0EUHLeye"
      },
      "source": [
        "> Note: About why we set `reduction` to `'none'`, please check this [tutorial](https://www.tensorflow.org/tutorials/distribute/custom_training#define_the_loss_function). In particular, read the paragraph. If using `tf.keras.losses` classes (as in the example below), the loss reduction needs to be explicitly specified to be one of `NONE` or `SUM`. `AUTO` and `SUM_OVER_BATCH_SIZE` are disallowed when used with `tf.distribute.Strategy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqZjpsNnMx76"
      },
      "source": [
        "> Note: About why we use `tf.nn.compute_average_loss`, please check this [tutorial](https://www.tensorflow.org/tutorials/distribute/custom_training#define_the_loss_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4-6G4hGNJWO"
      },
      "source": [
        "> Warning: While trained with `BATCH_SIZE = 8 * strategy.num_replicas_in_sync`, I got `nan` values. Since we pass probability distribution to `CategoricalCrossentropy` with `from_logits = False`, which has numerical unstability issue, we use the same trick in the source code to avoid such unstabiltiy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdsMl7f2KX0I"
      },
      "source": [
        "from tensorflow.python.ops import clip_ops\r\n",
        "from tensorflow.python.framework import constant_op"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ycNjziFJ-Lv"
      },
      "source": [
        "def _constant_to_tensor(x, dtype):\r\n",
        "    return constant_op.constant(x, dtype=dtype)\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    loss_object = tf.keras.losses.CategoricalCrossentropy(\r\n",
        "        from_logits=False, reduction='none', label_smoothing=0.1)\r\n",
        "    \r\n",
        "    def loss_function(labels, prob_dists, sample_weights=1.0):\r\n",
        "        epsilon_ = _constant_to_tensor(tf.keras.backend.epsilon(), prob_dists.dtype.base_dtype)\r\n",
        "        prob_dists = clip_ops.clip_by_value(prob_dists, epsilon_, 1 - epsilon_)\r\n",
        "        labels = tf.keras.backend.one_hot(labels, NCLASSES)\r\n",
        "        loss = loss_object(labels, prob_dists)\r\n",
        "        loss = tf.nn.compute_average_loss(loss, global_batch_size=BATCH_SIZE)\r\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlIz4OJyQt5u"
      },
      "source": [
        "## Custom Metric Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IzOkmFeQ4bU"
      },
      "source": [
        "def get_metrics(name):\r\n",
        "    loss = tf.keras.metrics.Mean(name=f'{name}_loss')\r\n",
        "    acc = tf.keras.metrics.SparseCategoricalAccuracy(name=f'{name}_acc')\r\n",
        "    return loss, acc\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    train_loss_obj, train_acc_obj = get_metrics('train')\r\n",
        "    valid_loss_obj, valid_acc_obj = get_metrics('valid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3llQSJ2RmOq"
      },
      "source": [
        "## Custom Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Noyje7-H-6Dz"
      },
      "source": [
        "The default runtime in TensorFlow 2.0 is eager execution. As such, our training loop above executes eagerly.\r\n",
        "this is great for debugging, but graph compilation has a definite performace advantage. Describing your computation as a static graph enables the framework to apply global performance optimizations. This is impossible when the frameworks is constrained to greedly execute one operation after another, with no knowledge of what comes next.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECosxTZ4STnQ"
      },
      "source": [
        "train_input_signature = [\r\n",
        "    tf.TensorSpec(shape=(None, None, None, None), dtype=tf.float32),\r\n",
        "    tf.TensorSpec(shape=(None,), dtype=tf.int32)\r\n",
        "]\r\n",
        "valid_input_signature = train_input_signature\r\n",
        "test_input_signature = [\r\n",
        "    tf.TensorSpec(shape=(None, None, None, None), dtype=tf.float32),\r\n",
        "]\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    @tf.function(input_signature=train_input_signature)\r\n",
        "    def train_step(images, labels):\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            prob_dists = flower_classifier(images, training=True)\r\n",
        "            loss = loss_function(labels, prob_dists)\r\n",
        "            train_acc_obj(labels, prob_dists)\r\n",
        "\r\n",
        "        grads = tape.gradient(loss, flower_classifier.trainable_variables)\r\n",
        "        grads, global_norm = tf.clip_by_global_norm(grads, clip_norm=1.0)\r\n",
        "        opt.apply_gradients(zip(grads, flower_classifier.trainable_variables))\r\n",
        "        return loss\r\n",
        "    \r\n",
        "    @tf.function\r\n",
        "    def distributed_train_step(inputs):\r\n",
        "        (images, labels) = inputs\r\n",
        "        loss = strategy.run(train_step, args=(images, labels))\r\n",
        "\r\n",
        "    @tf.function(input_signature=valid_input_signature)\r\n",
        "    def valid_step(images, labels):\r\n",
        "        prob_dists =flower_classifier(images, training=False)\r\n",
        "        loss = loss_function(labels, prob_dists, sample_weights=None)\r\n",
        "        valid_acc_obj(labels, prob_dists)\r\n",
        "        return loss, prob_dists\r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def distributed_valid_step(inputs):\r\n",
        "        (images, labels) = inputs\r\n",
        "        loss, prob_dists = strategy.run(valid_step, args=(images,labels))\r\n",
        "        return loss, prob_dists\r\n",
        "\r\n",
        "    @tf.function(input_signature=test_input_signature)\r\n",
        "    def test_step(images):\r\n",
        "        prob_dists = flower_classifier(images, training=False)\r\n",
        "        return prob_dists\r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def distributed_test_step(inputs):\r\n",
        "        images = inputs\r\n",
        "        prob_dists = strategy.run(test_step, args=(images,))\r\n",
        "        return prob_dists\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hehsTCLvIdAW"
      },
      "source": [
        "keys = ['train_loss', 'train_acc', 'valid_loss', 'valid_acc',\r\n",
        "        'valid_f1', 'valid_precision', 'valid_recall', 'model_coefs']\r\n",
        "history = { k:[] for k in keys}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSjHX5k-4sHM"
      },
      "source": [
        "TRAIN_NSTEPS = math.ceil(count_data_items(train_filenames) / BATCH_SIZE)\r\n",
        "VALID_NSTEPS = math.ceil(count_data_items(valid_filenames) / BATCH_SIZE)\r\n",
        "TEST_NSTEPS = math.ceil(count_data_items(test_filenames) / BATCH_SIZE)\r\n",
        "(TRAIN_NSTEPS, VALID_NSTEPS, TEST_NSTEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpoQTTsV-OWg"
      },
      "source": [
        "valid_ds = get_valid_dataset(valid_filenames, ordered=True)\r\n",
        "valid_dist_ds = strategy.experimental_distribute_dataset(valid_ds)\r\n",
        "\r\n",
        "test_ds = get_test_dataset(test_filenames, ordered=True).map(lambda im,lbl: im)\r\n",
        "test_dist_ds = strategy.experimental_distribute_dataset(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAJPDvhyHFHB"
      },
      "source": [
        "cm_trues = (valid_ds.map(lambda im,lbl: lbl)\r\n",
        "                    .unbatch()\r\n",
        "                    .batch(count_data_items(valid_filenames))\r\n",
        "                    .as_numpy_iterator()\r\n",
        "                    .next())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwy5T98j_WHy"
      },
      "source": [
        "The return values of `strategy.experiment_run` are actually `PerReplica` objects. For `valid_step` we defined above, the return value is a tuple of 2 `PerReplica` object. The 2nd element in the return value is `prob_dists`, and it looks like.\r\n",
        "```python\r\n",
        "PerReplica:{\r\n",
        "            0 /job:worker/replica:0/task:0/device:TPU:0: tf.Tensor(..., shape=(16, 104), dtype=float32),\r\n",
        "            1 /job:worker/replica:0/task:0/device:TPU:0: tf.Tensor(..., shape=(16, 104), dtype=float32),\r\n",
        "            ...\r\n",
        "            7 /job:worker/replica:0/task:0/device:TPU:0: tf.Tensor(..., shape=(16, 104), dtype=float32)\r\n",
        "        }\r\n",
        "```\r\n",
        "The 1st element in the return value is `loss`. It's similar to the above, but a scaler, so we have to convert each of them to a single tf.Tensor manually.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MddMucERJOFE"
      },
      "source": [
        "for epoch in range(EPOCHS):\r\n",
        "    train_ds = get_train_dataset(train_filenames)\r\n",
        "    train_ds = train_ds.take(2)\r\n",
        "    train_dist_ds = strategy.experimental_distribute_dataset(train_ds)\r\n",
        "\r\n",
        "    train_loss_obj.reset_states()\r\n",
        "    train_acc_obj.reset_states()\r\n",
        "    valid_loss_obj.reset_states()\r\n",
        "    valid_acc_obj.reset_states()\r\n",
        "\r\n",
        "    for ibatch, inputs in enumerate(train_dist_ds):\r\n",
        "        per_replica_train_loss = distributed_train_step(inputs)\r\n",
        "        train_loss = tf.stack(per_replica_train_loss.values, axis=0)\r\n",
        "        train_loss = tf.math_reduce_sum(train_loss)\r\n",
        "        train_loss_obj(train_loss)\r\n",
        "\r\n",
        "    # print epoch training results\r\n",
        "    # store the epoch training result\r\n",
        "    history['train_loss'].append(train_loss_obj.result())\r\n",
        "    history['train_acc'].append(train_acc_obj.result())\r\n",
        "\r\n",
        "    all_valid_preds = []\r\n",
        "    for ibatch, inputs in enumerate(valid_dist_ds):\r\n",
        "        per_replica_valid_loss, per_replica_valid_preds = distributed_valid_step(inputs)\r\n",
        "        valid_preds = tf.concat(per_replica_valid_preds.values, axis=0)\r\n",
        "        valid_preds = valid_preds.numpy()\r\n",
        "\r\n",
        "        all_valid_preds.append(valid_preds)\r\n",
        "\r\n",
        "        valid_loss = tf.stack(per_replica_valid_loss.values, axis=0)\r\n",
        "        valid_loss = tf.math.reduce_sum(valid_loss)\r\n",
        "        valid_loss_obj(valid_loss)\r\n",
        "\r\n",
        "    history['valid_loss'].append(valid_loss_obj.result())\r\n",
        "    history['valid_acc'].append(valid_acc_obj.result())\r\n",
        "    all_valid_preds = np.concatenate(all_valid_preds, axis=0, out=None)\r\n",
        "\r\n",
        "    cm_preds = np.argmax(all_valid_preds, axis=-1)\r\n",
        "    f1 = f1_score(cm_trues, cm_preds,\r\n",
        "                  labels=range(NCLASSES), average='macro')\r\n",
        "    precision = precision_score(cm_trues, cm_preds,\r\n",
        "                  labels=range(NCLASSES), average='macro')\r\n",
        "    recall = recall_score(cm_trues, cm_preds,\r\n",
        "                  labels=range(NCLASSES), average='macro')    \r\n",
        "\r\n",
        "    history['valid_f1'].append(f1)        \r\n",
        "    history['valid_precision'].append(precision)\r\n",
        "    history['valid_recall'].append(recall)\r\n",
        "    history['model_coefs'].append(flower_classifier.prob_dist_weight(tf.constant(1, shape=(1, 1))).numpy()[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}