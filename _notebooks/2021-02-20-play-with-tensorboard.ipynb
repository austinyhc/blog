{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "play-with-tensorboard.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8wEOtbOLpvK"
      },
      "source": [
        "# Play with TensorBoard\n",
        "> TensorBoard provides the visualization and tooling needed for machine learning experimentation\n",
        "\n",
        "- toc: true\n",
        "- badges: true\n",
        "- author: Austin Chen\n",
        "- categories: [tensorboard]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFlI6Q7bYo4q"
      },
      "source": [
        "TensorBoard is TensorFlow's visualization toolkit, enabling ones to track metrics like loss and accuracy, visualize the model graph, view histograms of weights, biases, or other tensors as they change over time, and much more. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1VFbYXoIwVH"
      },
      "source": [
        "#collapse-hide\n",
        "\n",
        "%load_ext tensorboard\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "pd.options.display.max_columns=25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M3cWtmeKvID",
        "outputId": "1c72110d-eb73-4b96-e0e8-f62a033ece7c"
      },
      "source": [
        "df = pd.read_csv(\"kc_house_data.csv\")\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21613, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "Us0b85OpLZCY",
        "outputId": "59b6b400-fc57-4fe4-e7a2-ffa2225cabda"
      },
      "source": [
        "df.head().T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>6414100192</td>\n",
              "      <td>5631500400</td>\n",
              "      <td>2487200875</td>\n",
              "      <td>1954400510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>20150218T000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>221900</td>\n",
              "      <td>538000</td>\n",
              "      <td>180000</td>\n",
              "      <td>604000</td>\n",
              "      <td>510000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bedrooms</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bathrooms</th>\n",
              "      <td>1</td>\n",
              "      <td>2.25</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_living</th>\n",
              "      <td>1180</td>\n",
              "      <td>2570</td>\n",
              "      <td>770</td>\n",
              "      <td>1960</td>\n",
              "      <td>1680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_lot</th>\n",
              "      <td>5650</td>\n",
              "      <td>7242</td>\n",
              "      <td>10000</td>\n",
              "      <td>5000</td>\n",
              "      <td>8080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>floors</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>waterfront</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>view</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>condition</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grade</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_above</th>\n",
              "      <td>1180</td>\n",
              "      <td>2170</td>\n",
              "      <td>770</td>\n",
              "      <td>1050</td>\n",
              "      <td>1680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_basement</th>\n",
              "      <td>0</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>910</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yr_built</th>\n",
              "      <td>1955</td>\n",
              "      <td>1951</td>\n",
              "      <td>1933</td>\n",
              "      <td>1965</td>\n",
              "      <td>1987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yr_renovated</th>\n",
              "      <td>0</td>\n",
              "      <td>1991</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zipcode</th>\n",
              "      <td>98178</td>\n",
              "      <td>98125</td>\n",
              "      <td>98028</td>\n",
              "      <td>98136</td>\n",
              "      <td>98074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lat</th>\n",
              "      <td>47.5112</td>\n",
              "      <td>47.721</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>47.6168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>long</th>\n",
              "      <td>-122.257</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>-122.045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_living15</th>\n",
              "      <td>1340</td>\n",
              "      <td>1690</td>\n",
              "      <td>2720</td>\n",
              "      <td>1360</td>\n",
              "      <td>1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_lot15</th>\n",
              "      <td>5650</td>\n",
              "      <td>7639</td>\n",
              "      <td>8062</td>\n",
              "      <td>5000</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             0                1                2  \\\n",
              "id                  7129300520       6414100192       5631500400   \n",
              "date           20141013T000000  20141209T000000  20150225T000000   \n",
              "price                   221900           538000           180000   \n",
              "bedrooms                     3                3                2   \n",
              "bathrooms                    1             2.25                1   \n",
              "sqft_living               1180             2570              770   \n",
              "sqft_lot                  5650             7242            10000   \n",
              "floors                       1                2                1   \n",
              "waterfront                   0                0                0   \n",
              "view                         0                0                0   \n",
              "condition                    3                3                3   \n",
              "grade                        7                7                6   \n",
              "sqft_above                1180             2170              770   \n",
              "sqft_basement                0              400                0   \n",
              "yr_built                  1955             1951             1933   \n",
              "yr_renovated                 0             1991                0   \n",
              "zipcode                  98178            98125            98028   \n",
              "lat                    47.5112           47.721          47.7379   \n",
              "long                  -122.257         -122.319         -122.233   \n",
              "sqft_living15             1340             1690             2720   \n",
              "sqft_lot15                5650             7639             8062   \n",
              "\n",
              "                             3                4  \n",
              "id                  2487200875       1954400510  \n",
              "date           20141209T000000  20150218T000000  \n",
              "price                   604000           510000  \n",
              "bedrooms                     4                3  \n",
              "bathrooms                    3                2  \n",
              "sqft_living               1960             1680  \n",
              "sqft_lot                  5000             8080  \n",
              "floors                       1                1  \n",
              "waterfront                   0                0  \n",
              "view                         0                0  \n",
              "condition                    5                3  \n",
              "grade                        7                8  \n",
              "sqft_above                1050             1680  \n",
              "sqft_basement              910                0  \n",
              "yr_built                  1965             1987  \n",
              "yr_renovated                 0                0  \n",
              "zipcode                  98136            98074  \n",
              "lat                    47.5208          47.6168  \n",
              "long                  -122.393         -122.045  \n",
              "sqft_living15             1360             1800  \n",
              "sqft_lot15                5000             7503  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nrKrtubLdaA",
        "outputId": "3b76c216-7c98-4098-8b30-1d3fbd092f10"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                 int64\n",
              "date              object\n",
              "price            float64\n",
              "bedrooms           int64\n",
              "bathrooms        float64\n",
              "sqft_living        int64\n",
              "sqft_lot           int64\n",
              "floors           float64\n",
              "waterfront         int64\n",
              "view               int64\n",
              "condition          int64\n",
              "grade              int64\n",
              "sqft_above         int64\n",
              "sqft_basement      int64\n",
              "yr_built           int64\n",
              "yr_renovated       int64\n",
              "zipcode            int64\n",
              "lat              float64\n",
              "long             float64\n",
              "sqft_living15      int64\n",
              "sqft_lot15         int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "EuMVLx_FMCFO",
        "outputId": "c1b9c5ba-7def-4d0a-cb84-b0502998eef3"
      },
      "source": [
        "df['year'] = pd.to_numeric(df['date'].str.slice(0,4))\n",
        "df['month'] = pd.to_numeric(df['date'].str.slice(4,6))\n",
        "df['day'] = pd.to_numeric(df['date'].str.slice(6,8))\n",
        "\n",
        "df.drop(['id', 'date'], axis=\"columns\", inplace=True)\n",
        "df.head().T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>221900.0000</td>\n",
              "      <td>538000.000</td>\n",
              "      <td>180000.0000</td>\n",
              "      <td>604000.0000</td>\n",
              "      <td>510000.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bedrooms</th>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>3.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bathrooms</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>2.250</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_living</th>\n",
              "      <td>1180.0000</td>\n",
              "      <td>2570.000</td>\n",
              "      <td>770.0000</td>\n",
              "      <td>1960.0000</td>\n",
              "      <td>1680.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_lot</th>\n",
              "      <td>5650.0000</td>\n",
              "      <td>7242.000</td>\n",
              "      <td>10000.0000</td>\n",
              "      <td>5000.0000</td>\n",
              "      <td>8080.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>floors</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>waterfront</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>view</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>condition</th>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>3.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grade</th>\n",
              "      <td>7.0000</td>\n",
              "      <td>7.000</td>\n",
              "      <td>6.0000</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>8.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_above</th>\n",
              "      <td>1180.0000</td>\n",
              "      <td>2170.000</td>\n",
              "      <td>770.0000</td>\n",
              "      <td>1050.0000</td>\n",
              "      <td>1680.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_basement</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>400.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>910.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yr_built</th>\n",
              "      <td>1955.0000</td>\n",
              "      <td>1951.000</td>\n",
              "      <td>1933.0000</td>\n",
              "      <td>1965.0000</td>\n",
              "      <td>1987.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yr_renovated</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>1991.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zipcode</th>\n",
              "      <td>98178.0000</td>\n",
              "      <td>98125.000</td>\n",
              "      <td>98028.0000</td>\n",
              "      <td>98136.0000</td>\n",
              "      <td>98074.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lat</th>\n",
              "      <td>47.5112</td>\n",
              "      <td>47.721</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>47.6168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>long</th>\n",
              "      <td>-122.2570</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>-122.2330</td>\n",
              "      <td>-122.3930</td>\n",
              "      <td>-122.0450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_living15</th>\n",
              "      <td>1340.0000</td>\n",
              "      <td>1690.000</td>\n",
              "      <td>2720.0000</td>\n",
              "      <td>1360.0000</td>\n",
              "      <td>1800.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_lot15</th>\n",
              "      <td>5650.0000</td>\n",
              "      <td>7639.000</td>\n",
              "      <td>8062.0000</td>\n",
              "      <td>5000.0000</td>\n",
              "      <td>7503.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <td>2014.0000</td>\n",
              "      <td>2014.000</td>\n",
              "      <td>2015.0000</td>\n",
              "      <td>2014.0000</td>\n",
              "      <td>2015.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>month</th>\n",
              "      <td>10.0000</td>\n",
              "      <td>12.000</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>12.0000</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>day</th>\n",
              "      <td>13.0000</td>\n",
              "      <td>9.000</td>\n",
              "      <td>25.0000</td>\n",
              "      <td>9.0000</td>\n",
              "      <td>18.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         0           1            2            3            4\n",
              "price          221900.0000  538000.000  180000.0000  604000.0000  510000.0000\n",
              "bedrooms            3.0000       3.000       2.0000       4.0000       3.0000\n",
              "bathrooms           1.0000       2.250       1.0000       3.0000       2.0000\n",
              "sqft_living      1180.0000    2570.000     770.0000    1960.0000    1680.0000\n",
              "sqft_lot         5650.0000    7242.000   10000.0000    5000.0000    8080.0000\n",
              "floors              1.0000       2.000       1.0000       1.0000       1.0000\n",
              "waterfront          0.0000       0.000       0.0000       0.0000       0.0000\n",
              "view                0.0000       0.000       0.0000       0.0000       0.0000\n",
              "condition           3.0000       3.000       3.0000       5.0000       3.0000\n",
              "grade               7.0000       7.000       6.0000       7.0000       8.0000\n",
              "sqft_above       1180.0000    2170.000     770.0000    1050.0000    1680.0000\n",
              "sqft_basement       0.0000     400.000       0.0000     910.0000       0.0000\n",
              "yr_built         1955.0000    1951.000    1933.0000    1965.0000    1987.0000\n",
              "yr_renovated        0.0000    1991.000       0.0000       0.0000       0.0000\n",
              "zipcode         98178.0000   98125.000   98028.0000   98136.0000   98074.0000\n",
              "lat                47.5112      47.721      47.7379      47.5208      47.6168\n",
              "long             -122.2570    -122.319    -122.2330    -122.3930    -122.0450\n",
              "sqft_living15    1340.0000    1690.000    2720.0000    1360.0000    1800.0000\n",
              "sqft_lot15       5650.0000    7639.000    8062.0000    5000.0000    7503.0000\n",
              "year             2014.0000    2014.000    2015.0000    2014.0000    2015.0000\n",
              "month              10.0000      12.000       2.0000      12.0000       2.0000\n",
              "day                13.0000       9.000      25.0000       9.0000      18.0000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LSp6RuQMnyf"
      },
      "source": [
        "n = df.shape[0]\n",
        "ids = np.random.permutation(n)\n",
        "train_ids = ids[:int(n * .6)]\n",
        "valid_ids = ids[int(n * .4) : int(n * .8)]\n",
        "test_ids = ids[int(n * .8):]\n",
        "\n",
        "train_data = df.loc[train_ids]\n",
        "valid_data = df.loc[valid_ids]\n",
        "test_data = df.loc[test_ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3AwV47vNac1"
      },
      "source": [
        "train_valid_data = pd.concat([train_data, valid_data])\n",
        "mean = train_valid_data.mean()\n",
        "std = train_valid_data.std()\n",
        "train_data = (train_data - mean) / std\n",
        "valid_data = (valid_data - mean) / std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzDr_lgcN0jA"
      },
      "source": [
        "train_x = np.array(train_data.drop('price', axis='columns')).astype('float32')\n",
        "train_y = np.array(train_data['price']).astype('float32')\n",
        "\n",
        "valid_x = np.array(valid_data.drop('price', axis='columns')).astype('float32')\n",
        "valid_y = np.array(valid_data['price']).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9G0UNg1OKIj",
        "outputId": "2a79bb85-b9d2-434e-85c8-bda73f48e4a1"
      },
      "source": [
        "train_x.shape, valid_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12967, 21), (8645, 21))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DQhfNETOWN_"
      },
      "source": [
        "model = tf.keras.Sequential(name='model-1')\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(21,)))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0hiWpigO0Y5",
        "outputId": "ab73512c-91b8-46ec-bfce-2889834c4682"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model-1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                1408      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 5,633\n",
            "Trainable params: 5,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XUOpbo6Oy7A"
      },
      "source": [
        "model.compile(tf.keras.optimizers.Adam(0.001),\n",
        "              loss = tf.keras.losses.MeanSquaredError(),\n",
        "              metrics=[tf.keras.metrics.MeanAbsoluteError()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJXgPECIPIxm"
      },
      "source": [
        "log_dir = \"logs/model_1/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('models/best-model-1.h5',\n",
        "                                                monitor='val_mean_absolute_error',\n",
        "                                                save_best_only=True,\n",
        "                                                mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-lNKjs-UKcL",
        "outputId": "94b4ac99-0084-45dd-f00c-d13edb4ba021"
      },
      "source": [
        "#collapse_output\n",
        "history = model.fit(train_x, train_y,\n",
        "                    batch_size=64,\n",
        "                    epochs=300,\n",
        "                    validation_data=(valid_x, valid_y),\n",
        "                    callbacks=[tensorboard_callback,\n",
        "                               checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "203/203 [==============================] - 4s 7ms/step - loss: 0.4115 - mean_absolute_error: 0.4102 - val_loss: 0.2153 - val_mean_absolute_error: 0.2894\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.2147 - mean_absolute_error: 0.2880 - val_loss: 0.1866 - val_mean_absolute_error: 0.2655\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.1913 - mean_absolute_error: 0.2684 - val_loss: 0.1700 - val_mean_absolute_error: 0.2589\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.1584 - mean_absolute_error: 0.2487 - val_loss: 0.1553 - val_mean_absolute_error: 0.2431\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.1488 - mean_absolute_error: 0.2400 - val_loss: 0.1401 - val_mean_absolute_error: 0.2347\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.1440 - mean_absolute_error: 0.2348 - val_loss: 0.1443 - val_mean_absolute_error: 0.2353\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.1418 - mean_absolute_error: 0.2270 - val_loss: 0.1287 - val_mean_absolute_error: 0.2207\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.1164 - mean_absolute_error: 0.2130 - val_loss: 0.1201 - val_mean_absolute_error: 0.2155\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.1208 - mean_absolute_error: 0.2127 - val_loss: 0.1287 - val_mean_absolute_error: 0.2241\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.1097 - mean_absolute_error: 0.2055 - val_loss: 0.1197 - val_mean_absolute_error: 0.2123\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.1099 - mean_absolute_error: 0.2057 - val_loss: 0.1171 - val_mean_absolute_error: 0.2131\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.1007 - mean_absolute_error: 0.2010 - val_loss: 0.1153 - val_mean_absolute_error: 0.2086\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.1045 - mean_absolute_error: 0.2044 - val_loss: 0.1153 - val_mean_absolute_error: 0.2176\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0975 - mean_absolute_error: 0.1985 - val_loss: 0.1068 - val_mean_absolute_error: 0.2065\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0882 - mean_absolute_error: 0.1919 - val_loss: 0.1044 - val_mean_absolute_error: 0.1989\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0924 - mean_absolute_error: 0.1943 - val_loss: 0.1387 - val_mean_absolute_error: 0.2235\n",
            "Epoch 17/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0904 - mean_absolute_error: 0.1940 - val_loss: 0.1000 - val_mean_absolute_error: 0.1973\n",
            "Epoch 18/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0886 - mean_absolute_error: 0.1901 - val_loss: 0.1022 - val_mean_absolute_error: 0.1961\n",
            "Epoch 19/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0842 - mean_absolute_error: 0.1871 - val_loss: 0.1005 - val_mean_absolute_error: 0.1954\n",
            "Epoch 20/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0804 - mean_absolute_error: 0.1856 - val_loss: 0.1010 - val_mean_absolute_error: 0.1984\n",
            "Epoch 21/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0846 - mean_absolute_error: 0.1871 - val_loss: 0.0965 - val_mean_absolute_error: 0.1941\n",
            "Epoch 22/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0823 - mean_absolute_error: 0.1865 - val_loss: 0.0976 - val_mean_absolute_error: 0.1930\n",
            "Epoch 23/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0801 - mean_absolute_error: 0.1829 - val_loss: 0.1029 - val_mean_absolute_error: 0.2059\n",
            "Epoch 24/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0787 - mean_absolute_error: 0.1814 - val_loss: 0.0983 - val_mean_absolute_error: 0.1972\n",
            "Epoch 25/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0756 - mean_absolute_error: 0.1794 - val_loss: 0.0951 - val_mean_absolute_error: 0.1914\n",
            "Epoch 26/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0760 - mean_absolute_error: 0.1808 - val_loss: 0.0976 - val_mean_absolute_error: 0.1945\n",
            "Epoch 27/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0740 - mean_absolute_error: 0.1809 - val_loss: 0.0941 - val_mean_absolute_error: 0.1931\n",
            "Epoch 28/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0749 - mean_absolute_error: 0.1797 - val_loss: 0.0966 - val_mean_absolute_error: 0.1933\n",
            "Epoch 29/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0735 - mean_absolute_error: 0.1779 - val_loss: 0.0959 - val_mean_absolute_error: 0.1935\n",
            "Epoch 30/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0719 - mean_absolute_error: 0.1772 - val_loss: 0.0948 - val_mean_absolute_error: 0.1901\n",
            "Epoch 31/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0701 - mean_absolute_error: 0.1766 - val_loss: 0.1059 - val_mean_absolute_error: 0.2212\n",
            "Epoch 32/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0748 - mean_absolute_error: 0.1811 - val_loss: 0.0953 - val_mean_absolute_error: 0.1907\n",
            "Epoch 33/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0668 - mean_absolute_error: 0.1734 - val_loss: 0.1223 - val_mean_absolute_error: 0.2204\n",
            "Epoch 34/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0712 - mean_absolute_error: 0.1792 - val_loss: 0.0973 - val_mean_absolute_error: 0.1917\n",
            "Epoch 35/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0660 - mean_absolute_error: 0.1725 - val_loss: 0.0950 - val_mean_absolute_error: 0.2000\n",
            "Epoch 36/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0672 - mean_absolute_error: 0.1740 - val_loss: 0.0948 - val_mean_absolute_error: 0.1881\n",
            "Epoch 37/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0647 - mean_absolute_error: 0.1689 - val_loss: 0.0906 - val_mean_absolute_error: 0.1885\n",
            "Epoch 38/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0628 - mean_absolute_error: 0.1711 - val_loss: 0.0994 - val_mean_absolute_error: 0.1946\n",
            "Epoch 39/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0653 - mean_absolute_error: 0.1722 - val_loss: 0.0905 - val_mean_absolute_error: 0.1875\n",
            "Epoch 40/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0612 - mean_absolute_error: 0.1680 - val_loss: 0.0950 - val_mean_absolute_error: 0.1879\n",
            "Epoch 41/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0618 - mean_absolute_error: 0.1690 - val_loss: 0.0978 - val_mean_absolute_error: 0.1918\n",
            "Epoch 42/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0577 - mean_absolute_error: 0.1645 - val_loss: 0.0930 - val_mean_absolute_error: 0.1845\n",
            "Epoch 43/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0547 - mean_absolute_error: 0.1613 - val_loss: 0.0961 - val_mean_absolute_error: 0.1952\n",
            "Epoch 44/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0588 - mean_absolute_error: 0.1659 - val_loss: 0.0941 - val_mean_absolute_error: 0.1881\n",
            "Epoch 45/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0612 - mean_absolute_error: 0.1674 - val_loss: 0.0929 - val_mean_absolute_error: 0.1881\n",
            "Epoch 46/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0589 - mean_absolute_error: 0.1658 - val_loss: 0.0880 - val_mean_absolute_error: 0.1822\n",
            "Epoch 47/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0589 - mean_absolute_error: 0.1658 - val_loss: 0.0954 - val_mean_absolute_error: 0.1882\n",
            "Epoch 48/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0554 - mean_absolute_error: 0.1620 - val_loss: 0.0921 - val_mean_absolute_error: 0.1864\n",
            "Epoch 49/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0568 - mean_absolute_error: 0.1631 - val_loss: 0.0924 - val_mean_absolute_error: 0.1848\n",
            "Epoch 50/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0547 - mean_absolute_error: 0.1628 - val_loss: 0.0952 - val_mean_absolute_error: 0.1853\n",
            "Epoch 51/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0537 - mean_absolute_error: 0.1605 - val_loss: 0.0958 - val_mean_absolute_error: 0.1912\n",
            "Epoch 52/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0524 - mean_absolute_error: 0.1596 - val_loss: 0.0950 - val_mean_absolute_error: 0.1911\n",
            "Epoch 53/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0558 - mean_absolute_error: 0.1629 - val_loss: 0.0959 - val_mean_absolute_error: 0.1935\n",
            "Epoch 54/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0570 - mean_absolute_error: 0.1647 - val_loss: 0.0886 - val_mean_absolute_error: 0.1840\n",
            "Epoch 55/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0531 - mean_absolute_error: 0.1597 - val_loss: 0.0932 - val_mean_absolute_error: 0.1840\n",
            "Epoch 56/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0505 - mean_absolute_error: 0.1571 - val_loss: 0.0895 - val_mean_absolute_error: 0.1848\n",
            "Epoch 57/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0552 - mean_absolute_error: 0.1630 - val_loss: 0.0910 - val_mean_absolute_error: 0.1833\n",
            "Epoch 58/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0515 - mean_absolute_error: 0.1572 - val_loss: 0.0894 - val_mean_absolute_error: 0.1814\n",
            "Epoch 59/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0493 - mean_absolute_error: 0.1547 - val_loss: 0.0888 - val_mean_absolute_error: 0.1837\n",
            "Epoch 60/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0501 - mean_absolute_error: 0.1572 - val_loss: 0.0905 - val_mean_absolute_error: 0.1849\n",
            "Epoch 61/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0493 - mean_absolute_error: 0.1546 - val_loss: 0.0911 - val_mean_absolute_error: 0.1848\n",
            "Epoch 62/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0502 - mean_absolute_error: 0.1563 - val_loss: 0.0882 - val_mean_absolute_error: 0.1840\n",
            "Epoch 63/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0484 - mean_absolute_error: 0.1546 - val_loss: 0.0893 - val_mean_absolute_error: 0.1835\n",
            "Epoch 64/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0490 - mean_absolute_error: 0.1564 - val_loss: 0.0882 - val_mean_absolute_error: 0.1824\n",
            "Epoch 65/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0517 - mean_absolute_error: 0.1572 - val_loss: 0.0861 - val_mean_absolute_error: 0.1796\n",
            "Epoch 66/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0453 - mean_absolute_error: 0.1503 - val_loss: 0.0911 - val_mean_absolute_error: 0.1854\n",
            "Epoch 67/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0484 - mean_absolute_error: 0.1543 - val_loss: 0.0958 - val_mean_absolute_error: 0.1882\n",
            "Epoch 68/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0488 - mean_absolute_error: 0.1576 - val_loss: 0.0878 - val_mean_absolute_error: 0.1813\n",
            "Epoch 69/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0460 - mean_absolute_error: 0.1511 - val_loss: 0.0866 - val_mean_absolute_error: 0.1780\n",
            "Epoch 70/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0475 - mean_absolute_error: 0.1541 - val_loss: 0.0881 - val_mean_absolute_error: 0.1816\n",
            "Epoch 71/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0453 - mean_absolute_error: 0.1511 - val_loss: 0.1133 - val_mean_absolute_error: 0.1959\n",
            "Epoch 72/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0474 - mean_absolute_error: 0.1529 - val_loss: 0.0965 - val_mean_absolute_error: 0.1914\n",
            "Epoch 73/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0465 - mean_absolute_error: 0.1535 - val_loss: 0.0856 - val_mean_absolute_error: 0.1795\n",
            "Epoch 74/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0452 - mean_absolute_error: 0.1494 - val_loss: 0.0911 - val_mean_absolute_error: 0.1838\n",
            "Epoch 75/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0445 - mean_absolute_error: 0.1497 - val_loss: 0.0901 - val_mean_absolute_error: 0.1816\n",
            "Epoch 76/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0455 - mean_absolute_error: 0.1502 - val_loss: 0.0987 - val_mean_absolute_error: 0.1849\n",
            "Epoch 77/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0497 - mean_absolute_error: 0.1566 - val_loss: 0.0870 - val_mean_absolute_error: 0.1807\n",
            "Epoch 78/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0430 - mean_absolute_error: 0.1481 - val_loss: 0.0880 - val_mean_absolute_error: 0.1818\n",
            "Epoch 79/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0443 - mean_absolute_error: 0.1500 - val_loss: 0.0857 - val_mean_absolute_error: 0.1783\n",
            "Epoch 80/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0426 - mean_absolute_error: 0.1478 - val_loss: 0.0905 - val_mean_absolute_error: 0.1808\n",
            "Epoch 81/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0444 - mean_absolute_error: 0.1476 - val_loss: 0.0869 - val_mean_absolute_error: 0.1794\n",
            "Epoch 82/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0462 - mean_absolute_error: 0.1511 - val_loss: 0.0871 - val_mean_absolute_error: 0.1777\n",
            "Epoch 83/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0422 - mean_absolute_error: 0.1475 - val_loss: 0.0876 - val_mean_absolute_error: 0.1832\n",
            "Epoch 84/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0477 - mean_absolute_error: 0.1522 - val_loss: 0.0859 - val_mean_absolute_error: 0.1831\n",
            "Epoch 85/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0420 - mean_absolute_error: 0.1476 - val_loss: 0.0907 - val_mean_absolute_error: 0.1864\n",
            "Epoch 86/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0435 - mean_absolute_error: 0.1489 - val_loss: 0.0839 - val_mean_absolute_error: 0.1785\n",
            "Epoch 87/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0413 - mean_absolute_error: 0.1451 - val_loss: 0.0897 - val_mean_absolute_error: 0.1854\n",
            "Epoch 88/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0409 - mean_absolute_error: 0.1454 - val_loss: 0.0856 - val_mean_absolute_error: 0.1772\n",
            "Epoch 89/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0414 - mean_absolute_error: 0.1445 - val_loss: 0.0853 - val_mean_absolute_error: 0.1759\n",
            "Epoch 90/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0410 - mean_absolute_error: 0.1452 - val_loss: 0.0874 - val_mean_absolute_error: 0.1770\n",
            "Epoch 91/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0390 - mean_absolute_error: 0.1421 - val_loss: 0.0858 - val_mean_absolute_error: 0.1791\n",
            "Epoch 92/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0393 - mean_absolute_error: 0.1426 - val_loss: 0.0852 - val_mean_absolute_error: 0.1783\n",
            "Epoch 93/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0440 - mean_absolute_error: 0.1505 - val_loss: 0.0899 - val_mean_absolute_error: 0.1795\n",
            "Epoch 94/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0384 - mean_absolute_error: 0.1407 - val_loss: 0.0847 - val_mean_absolute_error: 0.1742\n",
            "Epoch 95/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0386 - mean_absolute_error: 0.1409 - val_loss: 0.0932 - val_mean_absolute_error: 0.1831\n",
            "Epoch 96/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0495 - mean_absolute_error: 0.1501 - val_loss: 0.0947 - val_mean_absolute_error: 0.1827\n",
            "Epoch 97/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0425 - mean_absolute_error: 0.1465 - val_loss: 0.0859 - val_mean_absolute_error: 0.1754\n",
            "Epoch 98/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0373 - mean_absolute_error: 0.1396 - val_loss: 0.0862 - val_mean_absolute_error: 0.1813\n",
            "Epoch 99/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0395 - mean_absolute_error: 0.1434 - val_loss: 0.0886 - val_mean_absolute_error: 0.1789\n",
            "Epoch 100/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0382 - mean_absolute_error: 0.1412 - val_loss: 0.0915 - val_mean_absolute_error: 0.1858\n",
            "Epoch 101/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0386 - mean_absolute_error: 0.1429 - val_loss: 0.0948 - val_mean_absolute_error: 0.1834\n",
            "Epoch 102/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0401 - mean_absolute_error: 0.1433 - val_loss: 0.0945 - val_mean_absolute_error: 0.1830\n",
            "Epoch 103/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0393 - mean_absolute_error: 0.1447 - val_loss: 0.0878 - val_mean_absolute_error: 0.1784\n",
            "Epoch 104/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0385 - mean_absolute_error: 0.1425 - val_loss: 0.0856 - val_mean_absolute_error: 0.1756\n",
            "Epoch 105/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0379 - mean_absolute_error: 0.1396 - val_loss: 0.0865 - val_mean_absolute_error: 0.1824\n",
            "Epoch 106/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0409 - mean_absolute_error: 0.1448 - val_loss: 0.0889 - val_mean_absolute_error: 0.1791\n",
            "Epoch 107/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0373 - mean_absolute_error: 0.1395 - val_loss: 0.0866 - val_mean_absolute_error: 0.1796\n",
            "Epoch 108/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0369 - mean_absolute_error: 0.1390 - val_loss: 0.0878 - val_mean_absolute_error: 0.1756\n",
            "Epoch 109/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0351 - mean_absolute_error: 0.1378 - val_loss: 0.0833 - val_mean_absolute_error: 0.1750\n",
            "Epoch 110/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0365 - mean_absolute_error: 0.1395 - val_loss: 0.0873 - val_mean_absolute_error: 0.1756\n",
            "Epoch 111/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0364 - mean_absolute_error: 0.1387 - val_loss: 0.0848 - val_mean_absolute_error: 0.1784\n",
            "Epoch 112/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0356 - mean_absolute_error: 0.1388 - val_loss: 0.0872 - val_mean_absolute_error: 0.1762\n",
            "Epoch 113/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0365 - mean_absolute_error: 0.1384 - val_loss: 0.0884 - val_mean_absolute_error: 0.1766\n",
            "Epoch 114/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0368 - mean_absolute_error: 0.1388 - val_loss: 0.0858 - val_mean_absolute_error: 0.1764\n",
            "Epoch 115/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0361 - mean_absolute_error: 0.1386 - val_loss: 0.0873 - val_mean_absolute_error: 0.1772\n",
            "Epoch 116/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0397 - mean_absolute_error: 0.1426 - val_loss: 0.0838 - val_mean_absolute_error: 0.1747\n",
            "Epoch 117/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0377 - mean_absolute_error: 0.1413 - val_loss: 0.0935 - val_mean_absolute_error: 0.1806\n",
            "Epoch 118/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0382 - mean_absolute_error: 0.1417 - val_loss: 0.0870 - val_mean_absolute_error: 0.1754\n",
            "Epoch 119/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0372 - mean_absolute_error: 0.1402 - val_loss: 0.0877 - val_mean_absolute_error: 0.1819\n",
            "Epoch 120/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0361 - mean_absolute_error: 0.1389 - val_loss: 0.0841 - val_mean_absolute_error: 0.1735\n",
            "Epoch 121/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0364 - mean_absolute_error: 0.1371 - val_loss: 0.0882 - val_mean_absolute_error: 0.1788\n",
            "Epoch 122/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0333 - mean_absolute_error: 0.1342 - val_loss: 0.0853 - val_mean_absolute_error: 0.1756\n",
            "Epoch 123/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0344 - mean_absolute_error: 0.1355 - val_loss: 0.0820 - val_mean_absolute_error: 0.1710\n",
            "Epoch 124/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0347 - mean_absolute_error: 0.1350 - val_loss: 0.0858 - val_mean_absolute_error: 0.1748\n",
            "Epoch 125/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0352 - mean_absolute_error: 0.1377 - val_loss: 0.0867 - val_mean_absolute_error: 0.1774\n",
            "Epoch 126/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0336 - mean_absolute_error: 0.1343 - val_loss: 0.0875 - val_mean_absolute_error: 0.1802\n",
            "Epoch 127/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0359 - mean_absolute_error: 0.1368 - val_loss: 0.0855 - val_mean_absolute_error: 0.1784\n",
            "Epoch 128/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0367 - mean_absolute_error: 0.1400 - val_loss: 0.0896 - val_mean_absolute_error: 0.1769\n",
            "Epoch 129/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0339 - mean_absolute_error: 0.1345 - val_loss: 0.0869 - val_mean_absolute_error: 0.1797\n",
            "Epoch 130/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0358 - mean_absolute_error: 0.1375 - val_loss: 0.0916 - val_mean_absolute_error: 0.1810\n",
            "Epoch 131/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0351 - mean_absolute_error: 0.1369 - val_loss: 0.0874 - val_mean_absolute_error: 0.1765\n",
            "Epoch 132/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0338 - mean_absolute_error: 0.1341 - val_loss: 0.0838 - val_mean_absolute_error: 0.1734\n",
            "Epoch 133/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0334 - mean_absolute_error: 0.1334 - val_loss: 0.0870 - val_mean_absolute_error: 0.1760\n",
            "Epoch 134/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0357 - mean_absolute_error: 0.1387 - val_loss: 0.0825 - val_mean_absolute_error: 0.1775\n",
            "Epoch 135/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0362 - mean_absolute_error: 0.1399 - val_loss: 0.0811 - val_mean_absolute_error: 0.1735\n",
            "Epoch 136/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0339 - mean_absolute_error: 0.1355 - val_loss: 0.0869 - val_mean_absolute_error: 0.1772\n",
            "Epoch 137/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0377 - mean_absolute_error: 0.1400 - val_loss: 0.0832 - val_mean_absolute_error: 0.1735\n",
            "Epoch 138/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0348 - mean_absolute_error: 0.1357 - val_loss: 0.0837 - val_mean_absolute_error: 0.1729\n",
            "Epoch 139/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0335 - mean_absolute_error: 0.1351 - val_loss: 0.0836 - val_mean_absolute_error: 0.1722\n",
            "Epoch 140/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0341 - mean_absolute_error: 0.1347 - val_loss: 0.0863 - val_mean_absolute_error: 0.1781\n",
            "Epoch 141/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0332 - mean_absolute_error: 0.1348 - val_loss: 0.0853 - val_mean_absolute_error: 0.1728\n",
            "Epoch 142/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0325 - mean_absolute_error: 0.1326 - val_loss: 0.0833 - val_mean_absolute_error: 0.1714\n",
            "Epoch 143/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0317 - mean_absolute_error: 0.1298 - val_loss: 0.0932 - val_mean_absolute_error: 0.1821\n",
            "Epoch 144/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0334 - mean_absolute_error: 0.1341 - val_loss: 0.0877 - val_mean_absolute_error: 0.1778\n",
            "Epoch 145/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0335 - mean_absolute_error: 0.1345 - val_loss: 0.0918 - val_mean_absolute_error: 0.1801\n",
            "Epoch 146/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0343 - mean_absolute_error: 0.1356 - val_loss: 0.0865 - val_mean_absolute_error: 0.1724\n",
            "Epoch 147/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0336 - mean_absolute_error: 0.1323 - val_loss: 0.0857 - val_mean_absolute_error: 0.1761\n",
            "Epoch 148/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0319 - mean_absolute_error: 0.1317 - val_loss: 0.0849 - val_mean_absolute_error: 0.1723\n",
            "Epoch 149/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0321 - mean_absolute_error: 0.1328 - val_loss: 0.0889 - val_mean_absolute_error: 0.1758\n",
            "Epoch 150/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0324 - mean_absolute_error: 0.1319 - val_loss: 0.0887 - val_mean_absolute_error: 0.1754\n",
            "Epoch 151/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0340 - mean_absolute_error: 0.1351 - val_loss: 0.0912 - val_mean_absolute_error: 0.1878\n",
            "Epoch 152/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0419 - mean_absolute_error: 0.1455 - val_loss: 0.0940 - val_mean_absolute_error: 0.1804\n",
            "Epoch 153/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0341 - mean_absolute_error: 0.1347 - val_loss: 0.0867 - val_mean_absolute_error: 0.1728\n",
            "Epoch 154/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0317 - mean_absolute_error: 0.1304 - val_loss: 0.0845 - val_mean_absolute_error: 0.1743\n",
            "Epoch 155/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0327 - mean_absolute_error: 0.1330 - val_loss: 0.0845 - val_mean_absolute_error: 0.1735\n",
            "Epoch 156/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0313 - mean_absolute_error: 0.1307 - val_loss: 0.0805 - val_mean_absolute_error: 0.1701\n",
            "Epoch 157/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0306 - mean_absolute_error: 0.1297 - val_loss: 0.0848 - val_mean_absolute_error: 0.1737\n",
            "Epoch 158/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0299 - mean_absolute_error: 0.1279 - val_loss: 0.0875 - val_mean_absolute_error: 0.1771\n",
            "Epoch 159/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0339 - mean_absolute_error: 0.1345 - val_loss: 0.0885 - val_mean_absolute_error: 0.1763\n",
            "Epoch 160/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0355 - mean_absolute_error: 0.1369 - val_loss: 0.0844 - val_mean_absolute_error: 0.1734\n",
            "Epoch 161/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0303 - mean_absolute_error: 0.1281 - val_loss: 0.0848 - val_mean_absolute_error: 0.1725\n",
            "Epoch 162/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0314 - mean_absolute_error: 0.1294 - val_loss: 0.0852 - val_mean_absolute_error: 0.1742\n",
            "Epoch 163/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0310 - mean_absolute_error: 0.1289 - val_loss: 0.0827 - val_mean_absolute_error: 0.1727\n",
            "Epoch 164/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0308 - mean_absolute_error: 0.1294 - val_loss: 0.0865 - val_mean_absolute_error: 0.1743\n",
            "Epoch 165/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0314 - mean_absolute_error: 0.1297 - val_loss: 0.0858 - val_mean_absolute_error: 0.1754\n",
            "Epoch 166/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0378 - mean_absolute_error: 0.1383 - val_loss: 0.0866 - val_mean_absolute_error: 0.1780\n",
            "Epoch 167/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0320 - mean_absolute_error: 0.1316 - val_loss: 0.0825 - val_mean_absolute_error: 0.1723\n",
            "Epoch 168/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0307 - mean_absolute_error: 0.1297 - val_loss: 0.0837 - val_mean_absolute_error: 0.1804\n",
            "Epoch 169/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0322 - mean_absolute_error: 0.1322 - val_loss: 0.0831 - val_mean_absolute_error: 0.1730\n",
            "Epoch 170/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0332 - mean_absolute_error: 0.1336 - val_loss: 0.0834 - val_mean_absolute_error: 0.1714\n",
            "Epoch 171/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0329 - mean_absolute_error: 0.1314 - val_loss: 0.0929 - val_mean_absolute_error: 0.1790\n",
            "Epoch 172/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0335 - mean_absolute_error: 0.1332 - val_loss: 0.0900 - val_mean_absolute_error: 0.1782\n",
            "Epoch 173/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0317 - mean_absolute_error: 0.1309 - val_loss: 0.0834 - val_mean_absolute_error: 0.1733\n",
            "Epoch 174/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0300 - mean_absolute_error: 0.1286 - val_loss: 0.0862 - val_mean_absolute_error: 0.1791\n",
            "Epoch 175/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0322 - mean_absolute_error: 0.1335 - val_loss: 0.0860 - val_mean_absolute_error: 0.1716\n",
            "Epoch 176/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0300 - mean_absolute_error: 0.1280 - val_loss: 0.0863 - val_mean_absolute_error: 0.1748\n",
            "Epoch 177/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0316 - mean_absolute_error: 0.1297 - val_loss: 0.0876 - val_mean_absolute_error: 0.1761\n",
            "Epoch 178/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0300 - mean_absolute_error: 0.1283 - val_loss: 0.0850 - val_mean_absolute_error: 0.1724\n",
            "Epoch 179/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0300 - mean_absolute_error: 0.1280 - val_loss: 0.0892 - val_mean_absolute_error: 0.1774\n",
            "Epoch 180/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0338 - mean_absolute_error: 0.1330 - val_loss: 0.0807 - val_mean_absolute_error: 0.1716\n",
            "Epoch 181/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0305 - mean_absolute_error: 0.1291 - val_loss: 0.0900 - val_mean_absolute_error: 0.1772\n",
            "Epoch 182/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0292 - mean_absolute_error: 0.1276 - val_loss: 0.0837 - val_mean_absolute_error: 0.1746\n",
            "Epoch 183/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0301 - mean_absolute_error: 0.1287 - val_loss: 0.0879 - val_mean_absolute_error: 0.1717\n",
            "Epoch 184/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0287 - mean_absolute_error: 0.1252 - val_loss: 0.0851 - val_mean_absolute_error: 0.1752\n",
            "Epoch 185/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0313 - mean_absolute_error: 0.1310 - val_loss: 0.0858 - val_mean_absolute_error: 0.1735\n",
            "Epoch 186/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0295 - mean_absolute_error: 0.1283 - val_loss: 0.0849 - val_mean_absolute_error: 0.1729\n",
            "Epoch 187/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0315 - mean_absolute_error: 0.1309 - val_loss: 0.0867 - val_mean_absolute_error: 0.1757\n",
            "Epoch 188/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0356 - mean_absolute_error: 0.1363 - val_loss: 0.0915 - val_mean_absolute_error: 0.1815\n",
            "Epoch 189/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0350 - mean_absolute_error: 0.1332 - val_loss: 0.0869 - val_mean_absolute_error: 0.1724\n",
            "Epoch 190/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0299 - mean_absolute_error: 0.1281 - val_loss: 0.0841 - val_mean_absolute_error: 0.1726\n",
            "Epoch 191/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0283 - mean_absolute_error: 0.1251 - val_loss: 0.0827 - val_mean_absolute_error: 0.1712\n",
            "Epoch 192/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0293 - mean_absolute_error: 0.1271 - val_loss: 0.0860 - val_mean_absolute_error: 0.1757\n",
            "Epoch 193/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0294 - mean_absolute_error: 0.1265 - val_loss: 0.0845 - val_mean_absolute_error: 0.1720\n",
            "Epoch 194/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0304 - mean_absolute_error: 0.1278 - val_loss: 0.0904 - val_mean_absolute_error: 0.1800\n",
            "Epoch 195/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0315 - mean_absolute_error: 0.1302 - val_loss: 0.0915 - val_mean_absolute_error: 0.1788\n",
            "Epoch 196/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0299 - mean_absolute_error: 0.1280 - val_loss: 0.0837 - val_mean_absolute_error: 0.1729\n",
            "Epoch 197/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0299 - mean_absolute_error: 0.1280 - val_loss: 0.0837 - val_mean_absolute_error: 0.1695\n",
            "Epoch 198/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0309 - mean_absolute_error: 0.1286 - val_loss: 0.0877 - val_mean_absolute_error: 0.1749\n",
            "Epoch 199/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0310 - mean_absolute_error: 0.1290 - val_loss: 0.0840 - val_mean_absolute_error: 0.1741\n",
            "Epoch 200/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0287 - mean_absolute_error: 0.1249 - val_loss: 0.0895 - val_mean_absolute_error: 0.1775\n",
            "Epoch 201/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0297 - mean_absolute_error: 0.1282 - val_loss: 0.0866 - val_mean_absolute_error: 0.1749\n",
            "Epoch 202/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0295 - mean_absolute_error: 0.1262 - val_loss: 0.0903 - val_mean_absolute_error: 0.1857\n",
            "Epoch 203/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0292 - mean_absolute_error: 0.1261 - val_loss: 0.0823 - val_mean_absolute_error: 0.1708\n",
            "Epoch 204/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0288 - mean_absolute_error: 0.1259 - val_loss: 0.0829 - val_mean_absolute_error: 0.1725\n",
            "Epoch 205/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0293 - mean_absolute_error: 0.1266 - val_loss: 0.0871 - val_mean_absolute_error: 0.1743\n",
            "Epoch 206/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0290 - mean_absolute_error: 0.1252 - val_loss: 0.0938 - val_mean_absolute_error: 0.1870\n",
            "Epoch 207/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0309 - mean_absolute_error: 0.1298 - val_loss: 0.0845 - val_mean_absolute_error: 0.1705\n",
            "Epoch 208/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0341 - mean_absolute_error: 0.1333 - val_loss: 0.0937 - val_mean_absolute_error: 0.1822\n",
            "Epoch 209/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0326 - mean_absolute_error: 0.1305 - val_loss: 0.0872 - val_mean_absolute_error: 0.1714\n",
            "Epoch 210/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0306 - mean_absolute_error: 0.1298 - val_loss: 0.0835 - val_mean_absolute_error: 0.1696\n",
            "Epoch 211/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0333 - mean_absolute_error: 0.1302 - val_loss: 0.0863 - val_mean_absolute_error: 0.1711\n",
            "Epoch 212/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0284 - mean_absolute_error: 0.1245 - val_loss: 0.0880 - val_mean_absolute_error: 0.1709\n",
            "Epoch 213/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0271 - mean_absolute_error: 0.1226 - val_loss: 0.0834 - val_mean_absolute_error: 0.1740\n",
            "Epoch 214/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0286 - mean_absolute_error: 0.1269 - val_loss: 0.0866 - val_mean_absolute_error: 0.1724\n",
            "Epoch 215/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0284 - mean_absolute_error: 0.1247 - val_loss: 0.0916 - val_mean_absolute_error: 0.1765\n",
            "Epoch 216/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0292 - mean_absolute_error: 0.1267 - val_loss: 0.0890 - val_mean_absolute_error: 0.1759\n",
            "Epoch 217/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0285 - mean_absolute_error: 0.1255 - val_loss: 0.0861 - val_mean_absolute_error: 0.1729\n",
            "Epoch 218/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0277 - mean_absolute_error: 0.1247 - val_loss: 0.0844 - val_mean_absolute_error: 0.1714\n",
            "Epoch 219/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0363 - mean_absolute_error: 0.1341 - val_loss: 0.1008 - val_mean_absolute_error: 0.1855\n",
            "Epoch 220/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0384 - mean_absolute_error: 0.1372 - val_loss: 0.0863 - val_mean_absolute_error: 0.1727\n",
            "Epoch 221/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0294 - mean_absolute_error: 0.1258 - val_loss: 0.0856 - val_mean_absolute_error: 0.1733\n",
            "Epoch 222/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0266 - mean_absolute_error: 0.1217 - val_loss: 0.0854 - val_mean_absolute_error: 0.1713\n",
            "Epoch 223/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0272 - mean_absolute_error: 0.1225 - val_loss: 0.0840 - val_mean_absolute_error: 0.1687\n",
            "Epoch 224/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0291 - mean_absolute_error: 0.1256 - val_loss: 0.0874 - val_mean_absolute_error: 0.1713\n",
            "Epoch 225/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0269 - mean_absolute_error: 0.1225 - val_loss: 0.0822 - val_mean_absolute_error: 0.1707\n",
            "Epoch 226/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0265 - mean_absolute_error: 0.1206 - val_loss: 0.0836 - val_mean_absolute_error: 0.1729\n",
            "Epoch 227/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0277 - mean_absolute_error: 0.1226 - val_loss: 0.0834 - val_mean_absolute_error: 0.1701\n",
            "Epoch 228/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0284 - mean_absolute_error: 0.1242 - val_loss: 0.0854 - val_mean_absolute_error: 0.1704\n",
            "Epoch 229/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0303 - mean_absolute_error: 0.1275 - val_loss: 0.0856 - val_mean_absolute_error: 0.1722\n",
            "Epoch 230/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0285 - mean_absolute_error: 0.1254 - val_loss: 0.0868 - val_mean_absolute_error: 0.1732\n",
            "Epoch 231/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0268 - mean_absolute_error: 0.1217 - val_loss: 0.0891 - val_mean_absolute_error: 0.1744\n",
            "Epoch 232/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0343 - mean_absolute_error: 0.1327 - val_loss: 0.0867 - val_mean_absolute_error: 0.1721\n",
            "Epoch 233/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0316 - mean_absolute_error: 0.1294 - val_loss: 0.0850 - val_mean_absolute_error: 0.1708\n",
            "Epoch 234/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0279 - mean_absolute_error: 0.1245 - val_loss: 0.0837 - val_mean_absolute_error: 0.1701\n",
            "Epoch 235/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0295 - mean_absolute_error: 0.1261 - val_loss: 0.0865 - val_mean_absolute_error: 0.1699\n",
            "Epoch 236/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0266 - mean_absolute_error: 0.1219 - val_loss: 0.0902 - val_mean_absolute_error: 0.1753\n",
            "Epoch 237/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0297 - mean_absolute_error: 0.1281 - val_loss: 0.0883 - val_mean_absolute_error: 0.1740\n",
            "Epoch 238/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0276 - mean_absolute_error: 0.1223 - val_loss: 0.0853 - val_mean_absolute_error: 0.1778\n",
            "Epoch 239/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0296 - mean_absolute_error: 0.1276 - val_loss: 0.0833 - val_mean_absolute_error: 0.1700\n",
            "Epoch 240/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0272 - mean_absolute_error: 0.1224 - val_loss: 0.0906 - val_mean_absolute_error: 0.1745\n",
            "Epoch 241/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0305 - mean_absolute_error: 0.1283 - val_loss: 0.0869 - val_mean_absolute_error: 0.1749\n",
            "Epoch 242/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0290 - mean_absolute_error: 0.1253 - val_loss: 0.0889 - val_mean_absolute_error: 0.1729\n",
            "Epoch 243/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0267 - mean_absolute_error: 0.1211 - val_loss: 0.0866 - val_mean_absolute_error: 0.1721\n",
            "Epoch 244/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0280 - mean_absolute_error: 0.1245 - val_loss: 0.0854 - val_mean_absolute_error: 0.1723\n",
            "Epoch 245/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0278 - mean_absolute_error: 0.1236 - val_loss: 0.0837 - val_mean_absolute_error: 0.1686\n",
            "Epoch 246/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0273 - mean_absolute_error: 0.1229 - val_loss: 0.0838 - val_mean_absolute_error: 0.1712\n",
            "Epoch 247/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0394 - mean_absolute_error: 0.1359 - val_loss: 0.0871 - val_mean_absolute_error: 0.1707\n",
            "Epoch 248/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0316 - mean_absolute_error: 0.1273 - val_loss: 0.0845 - val_mean_absolute_error: 0.1698\n",
            "Epoch 249/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0276 - mean_absolute_error: 0.1219 - val_loss: 0.0858 - val_mean_absolute_error: 0.1715\n",
            "Epoch 250/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0253 - mean_absolute_error: 0.1195 - val_loss: 0.0864 - val_mean_absolute_error: 0.1706\n",
            "Epoch 251/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0263 - mean_absolute_error: 0.1209 - val_loss: 0.0858 - val_mean_absolute_error: 0.1697\n",
            "Epoch 252/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0248 - mean_absolute_error: 0.1179 - val_loss: 0.0823 - val_mean_absolute_error: 0.1684\n",
            "Epoch 253/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0283 - mean_absolute_error: 0.1233 - val_loss: 0.0862 - val_mean_absolute_error: 0.1721\n",
            "Epoch 254/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0276 - mean_absolute_error: 0.1236 - val_loss: 0.0911 - val_mean_absolute_error: 0.1849\n",
            "Epoch 255/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0266 - mean_absolute_error: 0.1224 - val_loss: 0.0859 - val_mean_absolute_error: 0.1705\n",
            "Epoch 256/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0253 - mean_absolute_error: 0.1191 - val_loss: 0.0848 - val_mean_absolute_error: 0.1702\n",
            "Epoch 257/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0257 - mean_absolute_error: 0.1200 - val_loss: 0.0852 - val_mean_absolute_error: 0.1728\n",
            "Epoch 258/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0282 - mean_absolute_error: 0.1248 - val_loss: 0.0899 - val_mean_absolute_error: 0.1742\n",
            "Epoch 259/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0315 - mean_absolute_error: 0.1289 - val_loss: 0.0860 - val_mean_absolute_error: 0.1703\n",
            "Epoch 260/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0344 - mean_absolute_error: 0.1312 - val_loss: 0.0849 - val_mean_absolute_error: 0.1732\n",
            "Epoch 261/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0268 - mean_absolute_error: 0.1220 - val_loss: 0.0918 - val_mean_absolute_error: 0.1908\n",
            "Epoch 262/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0288 - mean_absolute_error: 0.1268 - val_loss: 0.0839 - val_mean_absolute_error: 0.1686\n",
            "Epoch 263/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0261 - mean_absolute_error: 0.1196 - val_loss: 0.0875 - val_mean_absolute_error: 0.1718\n",
            "Epoch 264/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0278 - mean_absolute_error: 0.1229 - val_loss: 0.0846 - val_mean_absolute_error: 0.1745\n",
            "Epoch 265/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0267 - mean_absolute_error: 0.1218 - val_loss: 0.0853 - val_mean_absolute_error: 0.1710\n",
            "Epoch 266/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0258 - mean_absolute_error: 0.1203 - val_loss: 0.0866 - val_mean_absolute_error: 0.1720\n",
            "Epoch 267/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0273 - mean_absolute_error: 0.1223 - val_loss: 0.0889 - val_mean_absolute_error: 0.1729\n",
            "Epoch 268/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0316 - mean_absolute_error: 0.1300 - val_loss: 0.0859 - val_mean_absolute_error: 0.1704\n",
            "Epoch 269/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0267 - mean_absolute_error: 0.1208 - val_loss: 0.0862 - val_mean_absolute_error: 0.1727\n",
            "Epoch 270/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0260 - mean_absolute_error: 0.1208 - val_loss: 0.0893 - val_mean_absolute_error: 0.1735\n",
            "Epoch 271/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0258 - mean_absolute_error: 0.1197 - val_loss: 0.0851 - val_mean_absolute_error: 0.1683\n",
            "Epoch 272/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0251 - mean_absolute_error: 0.1181 - val_loss: 0.0871 - val_mean_absolute_error: 0.1710\n",
            "Epoch 273/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0251 - mean_absolute_error: 0.1186 - val_loss: 0.0849 - val_mean_absolute_error: 0.1712\n",
            "Epoch 274/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0306 - mean_absolute_error: 0.1275 - val_loss: 0.0848 - val_mean_absolute_error: 0.1699\n",
            "Epoch 275/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0243 - mean_absolute_error: 0.1174 - val_loss: 0.0857 - val_mean_absolute_error: 0.1746\n",
            "Epoch 276/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0264 - mean_absolute_error: 0.1214 - val_loss: 0.0895 - val_mean_absolute_error: 0.1772\n",
            "Epoch 277/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0268 - mean_absolute_error: 0.1215 - val_loss: 0.0883 - val_mean_absolute_error: 0.1726\n",
            "Epoch 278/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0278 - mean_absolute_error: 0.1231 - val_loss: 0.0865 - val_mean_absolute_error: 0.1743\n",
            "Epoch 279/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0289 - mean_absolute_error: 0.1248 - val_loss: 0.0967 - val_mean_absolute_error: 0.1790\n",
            "Epoch 280/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0275 - mean_absolute_error: 0.1218 - val_loss: 0.0856 - val_mean_absolute_error: 0.1712\n",
            "Epoch 281/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0264 - mean_absolute_error: 0.1220 - val_loss: 0.0856 - val_mean_absolute_error: 0.1717\n",
            "Epoch 282/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0272 - mean_absolute_error: 0.1220 - val_loss: 0.0855 - val_mean_absolute_error: 0.1697\n",
            "Epoch 283/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0294 - mean_absolute_error: 0.1266 - val_loss: 0.0849 - val_mean_absolute_error: 0.1682\n",
            "Epoch 284/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0252 - mean_absolute_error: 0.1188 - val_loss: 0.0847 - val_mean_absolute_error: 0.1683\n",
            "Epoch 285/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0251 - mean_absolute_error: 0.1177 - val_loss: 0.0869 - val_mean_absolute_error: 0.1741\n",
            "Epoch 286/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0287 - mean_absolute_error: 0.1243 - val_loss: 0.0864 - val_mean_absolute_error: 0.1723\n",
            "Epoch 287/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0279 - mean_absolute_error: 0.1225 - val_loss: 0.0903 - val_mean_absolute_error: 0.1718\n",
            "Epoch 288/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0255 - mean_absolute_error: 0.1188 - val_loss: 0.0863 - val_mean_absolute_error: 0.1709\n",
            "Epoch 289/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0247 - mean_absolute_error: 0.1172 - val_loss: 0.0870 - val_mean_absolute_error: 0.1734\n",
            "Epoch 290/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0249 - mean_absolute_error: 0.1187 - val_loss: 0.0858 - val_mean_absolute_error: 0.1686\n",
            "Epoch 291/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0246 - mean_absolute_error: 0.1180 - val_loss: 0.0850 - val_mean_absolute_error: 0.1701\n",
            "Epoch 292/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0260 - mean_absolute_error: 0.1207 - val_loss: 0.0917 - val_mean_absolute_error: 0.1748\n",
            "Epoch 293/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0277 - mean_absolute_error: 0.1221 - val_loss: 0.0851 - val_mean_absolute_error: 0.1693\n",
            "Epoch 294/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0239 - mean_absolute_error: 0.1156 - val_loss: 0.0847 - val_mean_absolute_error: 0.1727\n",
            "Epoch 295/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0256 - mean_absolute_error: 0.1200 - val_loss: 0.0890 - val_mean_absolute_error: 0.1713\n",
            "Epoch 296/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0277 - mean_absolute_error: 0.1216 - val_loss: 0.0839 - val_mean_absolute_error: 0.1700\n",
            "Epoch 297/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0270 - mean_absolute_error: 0.1221 - val_loss: 0.0848 - val_mean_absolute_error: 0.1714\n",
            "Epoch 298/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0272 - mean_absolute_error: 0.1224 - val_loss: 0.0851 - val_mean_absolute_error: 0.1684\n",
            "Epoch 299/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0254 - mean_absolute_error: 0.1199 - val_loss: 0.0870 - val_mean_absolute_error: 0.1718\n",
            "Epoch 300/300\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.0284 - mean_absolute_error: 0.1246 - val_loss: 0.0953 - val_mean_absolute_error: 0.1797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft-cea13jLpZ",
        "outputId": "0c5a2a35-a794-4b02-f423-bff51cbbec14"
      },
      "source": [
        "#hide\n",
        "!tensorboard dev upload \\\n",
        "  --logdir logs/model_1 \\\n",
        "  --name \"Blog: Play with TensorBoard\" \\\n",
        "  --description \"Simple comparison of several hyperparameters\" \\\n",
        "  --one_shot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-03 09:30:50.127962: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Data for the \"text\" plugin is now uploaded to TensorBoard.dev! Note that uploaded data is public. If you do not want to upload data for this plugin, use the \"--plugins\" command line argument.\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/MVQyms8BSVym5wG2ETdDyA/\n",
            "\n",
            "\u001b[1m[2021-03-03T09:30:52]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2021-03-03T09:30:53]\u001b[0m Total uploaded: 1200 scalars, 0 tensors, 1 binary objects (33.1 kB)\n",
            "\u001b[1m[2021-03-03T09:30:53]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/MVQyms8BSVym5wG2ETdDyA/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "-gewwKYjV1Yy",
        "outputId": "500cf5d9-4a3e-49a2-8f21-dc3894cb6b80"
      },
      "source": [
        "#collapse\n",
        "from  IPython import display\n",
        "display.IFrame(\n",
        "    src=\"https://tensorboard.dev/experiment/MVQyms8BSVym5wG2ETdDyA/\",\n",
        "    width = \"100%\",\n",
        "    height=\"800px\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800px\"\n",
              "            src=\"https://tensorboard.dev/experiment/MVQyms8BSVym5wG2ETdDyA/\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f157e1ba690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0ME0PtGbZBR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}