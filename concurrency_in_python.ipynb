{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "concurrency-in-python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPyJ0ysFgjmcST6X2TTwDFy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DflZi95-WPVQ"
      },
      "source": [
        "# Concurrency in Python\r\n",
        "> Concurrency\r\n",
        "\r\n",
        "- toc: true\r\n",
        "- badges: true\r\n",
        "- categories: [concurrency]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkHJKZqTW6vE"
      },
      "source": [
        "Discussios criticising Python often talk about how it is difficult to use Python for multithreaded work, poinging fingers at what is known as the global interpreter lock (affectionately referred to as a [GIL](https://opensource.com/article/17/4/grok-gil)) that prevents multiple threads of Python code from running simultaneously. Due to this, the PYthon multithreading modeule doesn't quite behave the way you would expect it to if you're like me coming from C++. It must be made clear that one can still wirte code in Python that runs concurrently or in parallel and make a stark difference in resulting performance, as long as certain things are taken into consideration. If you haven't read it yet, I suggest you take a look at Eqbal Quran's [article on concurrency and parallelism in Ruby](https://www.toptal.com/ruby/ruby-concurrency-and-parallelism-a-practical-primer).\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWgT1WpwWL8o"
      },
      "source": [
        "import os,json,logging,concurrent\r\n",
        "from pathlib import Path"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKx0RXqpWKGR"
      },
      "source": [
        "class ProcessPoolExecutor(concurrent.futures.ProcessPoolExecutor):\r\n",
        "    \"Same as Python's ProcessPoolExecutor, except can pass `max_workers==0` for serial execution\"\r\n",
        "    def __init__(self, max_workers=4, on_exc=print, pause=0, **kwargs):\r\n",
        "        if max_workers is None: max_workers=defaults.cpus\r\n",
        "        store_attr()\r\n",
        "        self.not_parallel = max_workers==0\r\n",
        "        if self.not_parallel: max_workers=1\r\n",
        "        super().__init__(max_workers, **kwargs)\r\n",
        "\r\n",
        "    def map(self, f, items, *args, timeout=None, chunksize=1, **kwargs):\r\n",
        "        self.lock = Manager().Lock()\r\n",
        "        g = partial(f, *args, **kwargs)\r\n",
        "        if self.not_parallel: return map(g, items)\r\n",
        "        _g = partial(_call, self.lock, self.pause, self.max_workers, g)\r\n",
        "        try: return super().map(_g, items, timeout=timeout, chunksize=chunksize)\r\n",
        "        except Exception as e: self.on_exc(e)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}