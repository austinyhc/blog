<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Jane Street Market Prediction | AUSTIN CAN HELP</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Jane Street Market Prediction" />
<meta name="author" content="Austin Chen" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Buy low, sell high. It sounds so easy…." />
<meta property="og:description" content="Buy low, sell high. It sounds so easy…." />
<link rel="canonical" href="https://austinyhc.github.io/blog/time%20series/stock/kaggle/2021/01/15/jane-street-market-prediction.html" />
<meta property="og:url" content="https://austinyhc.github.io/blog/time%20series/stock/kaggle/2021/01/15/jane-street-market-prediction.html" />
<meta property="og:site_name" content="AUSTIN CAN HELP" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-15T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://austinyhc.github.io/blog/time%20series/stock/kaggle/2021/01/15/jane-street-market-prediction.html","@type":"BlogPosting","headline":"Jane Street Market Prediction","dateModified":"2021-01-15T00:00:00-06:00","datePublished":"2021-01-15T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://austinyhc.github.io/blog/time%20series/stock/kaggle/2021/01/15/jane-street-market-prediction.html"},"author":{"@type":"Person","name":"Austin Chen"},"description":"Buy low, sell high. It sounds so easy….","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://austinyhc.github.io/blog/feed.xml" title="AUSTIN CAN HELP" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">AUSTIN CAN HELP</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Jane Street Market Prediction</h1><p class="page-description">Buy low, sell high. It sounds so easy….</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-01-15T00:00:00-06:00" itemprop="datePublished">
        Jan 15, 2021
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Austin Chen</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      12 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#time series">time series</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#stock">stock</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#kaggle">kaggle</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/austinyhc/blog/tree/master/_notebooks/jane-street-market-prediction.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/austinyhc/blog/blob/master/_notebooks/jane-street-market-prediction.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#1%-Better-Everyday">1% Better Everyday </a></li>
<li class="toc-entry toc-h1"><a href="#Overview">Overview </a></li>
<li class="toc-entry toc-h1"><a href="#Preworks">Preworks </a></li>
<li class="toc-entry toc-h1"><a href="#Exploration">Exploration </a></li>
<li class="toc-entry toc-h1"><a href="#HyperParameters">HyperParameters </a></li>
<li class="toc-entry toc-h1"><a href="#Data">Data </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Loading-data">Loading data </a></li>
<li class="toc-entry toc-h2"><a href="#Preparing-data">Preparing data </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Model">Model </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Building-the-autoencoder">Building the autoencoder </a></li>
<li class="toc-entry toc-h2"><a href="#Building-the-MLP">Building the MLP </a></li>
<li class="toc-entry toc-h2"><a href="#Defining-and-training-the-autoencoder">Defining and training the autoencoder </a></li>
<li class="toc-entry toc-h2"><a href="#Running-CV">Running CV </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/jane-street-market-prediction.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="1%-Better-Everyday">
<a class="anchor" href="#1%-Better-Everyday" aria-hidden="true"><span class="octicon octicon-link"></span></a>1% Better Everyday<a class="anchor-link" href="#1%-Better-Everyday"> </a>
</h1>
<ul>
<li>
<p>I see that autoencoders are widely being used in this competition. However, I am having some doubts on wether the autoencoded features really help the model. As shown in the notebook, the compressed features concatenated back into the original data as extra featues. For me personally, I've tried 2~3 different random seed and the variation on the results are large. It makes me wonder that the autoencoder is only useful on certain features, so dropping these from the autoencoder might be a good idea.</p>
</li>
<li>
<p>Maybe we can feed the autoencoded features to non-nn models e.g. Xgboost, CatBoost, CBM? <a href="https://www.kaggle.com/gregorycalvez/de-anonymization-time-aggregation-tags">refence</a></p>
</li>
<li>
<p>Maybe we need to remove correlated featues before generating autoencoded features.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Overview">
<a class="anchor" href="#Overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overview<a class="anchor-link" href="#Overview"> </a>
</h1>
<p>The efficient market hypothesis posits that markets cannot be beaten because asset prices will always reflect the fundamental value of the assets. In a perfectly efficient market, buyers and sellers would have all the agency and information needed to make rational trading decisions.</p>
<p>In reality, financial markets are not efficient. The purpose of this trading model is to identify arbitrage opportunities to "buy low and seell high". In other words, we exploit market inefficiencies to identify and decide whether to execute profitable trades.</p>
<p>The dataset, provided by Jane Street, contains an anonymized set of 129 features representing real stock market data. Each row in the dataset represents a trading opportunity, for which I predict an action value: 1 to amke the trade and 0 to pass on it. Due to the high demensionality of the dataset, I use Principal Components Analysis (PCA) to identify features to be used for supervised learning. The intuition is to compress the dataset and use it more efficiently. I then use XGBoost (extreme gradient boosting) - a hugely popular ML library due to its superior execution speed and model performance - to predict profitable trades. I also use Optuna (an automatic hyperparameter optimization software framework) to tune the hyperparameters of the classification model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Preworks">
<a class="anchor" href="#Preworks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preworks<a class="anchor-link" href="#Preworks"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">albumentations</span> <span class="k">as</span> <span class="nn">A</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">gc</span><span class="o">,</span> <span class="nn">cv2</span><span class="o">,</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">re</span><span class="o">,</span> <span class="nn">math</span><span class="o">,</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">json</span><span class="o">,</span> <span class="nn">pprint</span><span class="o">,</span> <span class="nn">pdb</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="nn">hub</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="kn">import</span> <span class="nn">dabl</span>
<span class="kn">import</span> <span class="nn">datatable</span> <span class="k">as</span> <span class="nn">dt</span>
<span class="kn">import</span> <span class="nn">kerastuner</span> <span class="k">as</span> <span class="nn">kt</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using TensorFlow v</span><span class="si">{</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Using TensorFlow v2.4.0
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#@title Notebook type { run: "auto", display-mode:"form" }</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">10120919</span>
<span class="n">DEBUG</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1">#@param {type:"boolean"}</span>
<span class="n">TRAIN</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1">#@param {type:"boolean"}</span>

<span class="k">def</span> <span class="nf">seed_everything</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'PYTHONHASHSEED'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'TF_DETERMINISTIC_OPS'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'1'</span>

<span class="n">GOOGLE</span> <span class="o">=</span> <span class="s1">'google.colab'</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_ipython</span><span class="p">())</span>
<span class="n">KAGGLE</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">GOOGLE</span>

<span class="n">seed_everything</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Running on </span><span class="si">{}</span><span class="s2">!"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
   <span class="s2">"Google Colab"</span> <span class="k">if</span> <span class="n">GOOGLE</span> <span class="k">else</span> <span class="s2">"Kaggle Kernel"</span>
<span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Running on Google Colab!
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Exploration">
<a class="anchor" href="#Exploration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Exploration<a class="anchor-link" href="#Exploration"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="HyperParameters">
<a class="anchor" href="#HyperParameters" aria-hidden="true"><span class="octicon octicon-link"></span></a>HyperParameters<a class="anchor-link" href="#HyperParameters"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Data">
<a class="anchor" href="#Data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data<a class="anchor-link" href="#Data"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loading-data">
<a class="anchor" href="#Loading-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loading data<a class="anchor-link" href="#Loading-data"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's try <code>datatable</code> to load the data, and then convert to a pandas dataframe.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">train_dt</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">fread</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">input_path</span><span class="si">}</span><span class="s2">train.csv"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 30.9 s, sys: 6.73 s, total: 37.6 s
Wall time: 3min 20s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_dt</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 5.35 s, sys: 4.15 s, total: 9.5 s
Wall time: 7.2 s
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The dataframe is <code>2390490</code> rows by <code>138</code> columns</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 2390491 entries, 0 to 2390490
Columns: 138 entries, date to ts_id
dtypes: float64(135), int32(3)
memory usage: 2.4 GB
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preparing-data">
<a class="anchor" href="#Preparing-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preparing data<a class="anchor-link" href="#Preparing-data"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">'date &gt; 85'</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># limit memory usage</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">astype</span><span class="p">({</span><span class="n">c</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">train_df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s1">'float64'</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span><span class="p">})</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">train_df</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">'weight &gt; 0'</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">train_df</span><span class="p">[</span><span class="s1">'action'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">train_df</span><span class="p">[</span><span class="s1">'resp_1'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span>
                      <span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">'resp_2'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span>
                      <span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">'resp_3'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span>
                      <span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">'resp_4'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span>
                      <span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">'resp'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'int'</span><span class="p">)</span>

<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">train_df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="s1">'feature'</span> <span class="ow">in</span> <span class="n">c</span><span class="p">]</span>
<span class="n">resp_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'resp_1'</span><span class="p">,</span> <span class="s1">'resp_2'</span><span class="p">,</span> <span class="s1">'resp_3'</span><span class="p">,</span> <span class="s1">'resp'</span><span class="p">,</span> <span class="s1">'resp_4'</span><span class="p">]</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([(</span><span class="n">train_df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'int'</span><span class="p">)</span> 
                        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">resp_cols</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
                        
<span class="n">f_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Modified code for <code>class GroupTimeSeriesSplit(_BaseKFold)</code>
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection._split</span> <span class="kn">import</span> <span class="n">_BaseKFold</span><span class="p">,</span> <span class="n">indexable</span><span class="p">,</span> <span class="n">_num_samples</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="n">_deprecate_positional_args</span>

<span class="k">class</span> <span class="nc">PurgedGroupTimeSeriesSplit</span><span class="p">(</span><span class="n">_BaseKFold</span><span class="p">):</span>
    <span class="sd">"""Time Series cross-validator variant with non-overlapping groups.</span>
<span class="sd">    Allows for a gap in groups to avoid potentially leaking info from</span>
<span class="sd">    train into test if the model has windowed or lag features.</span>
<span class="sd">    Provides train/test indices to split time series data samples</span>
<span class="sd">    that are observed at fixed time intervals according to a</span>
<span class="sd">    third-party provided group.</span>
<span class="sd">    In each split, test indices must be higher than before, and thus shuffling</span>
<span class="sd">    in cross validator is inappropriate.</span>
<span class="sd">    This cross-validation object is a variation of :class:`KFold`.</span>
<span class="sd">    In the kth split, it returns first k folds as train set and the</span>
<span class="sd">    (k+1)th fold as test set.</span>
<span class="sd">    The same group will not appear in two different folds (the number of</span>
<span class="sd">    distinct groups has to be at least equal to the number of folds).</span>
<span class="sd">    Note that unlike standard cross-validation methods, successive</span>
<span class="sd">    training sets are supersets of those that come before them.</span>
<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of splits. Must be at least 2.</span>
<span class="sd">    max_train_group_size : int, default=Inf</span>
<span class="sd">        Maximum group size for a single training set.</span>
<span class="sd">    group_gap : int, default=None</span>
<span class="sd">        Gap between train and test</span>
<span class="sd">    max_test_group_size : int, default=Inf</span>
<span class="sd">        We discard this number of groups from the end of each train split</span>
<span class="sd">    """</span>

    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                 <span class="o">*</span><span class="p">,</span>
                 <span class="n">max_train_group_size</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
                 <span class="n">max_test_group_size</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
                 <span class="n">group_gap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span>
                 <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_train_group_size</span> <span class="o">=</span> <span class="n">max_train_group_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">group_gap</span> <span class="o">=</span> <span class="n">group_gap</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_test_group_size</span> <span class="o">=</span> <span class="n">max_test_group_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">"""Generate indices to split data into training and test set.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>
<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            Always ignored, exists for compatibility.</span>
<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>
<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>
<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">"The 'groups' parameter should not be None"</span><span class="p">)</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span>
        <span class="n">group_gap</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_gap</span>
        <span class="n">max_test_group_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_test_group_size</span>
        <span class="n">max_train_group_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_train_group_size</span>
        <span class="n">n_folds</span> <span class="o">=</span> <span class="n">n_splits</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">group_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">return_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">unique_groups</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">ind</span><span class="p">)]</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">n_groups</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">groups</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="ow">in</span> <span class="n">group_dict</span><span class="p">):</span>
                <span class="n">group_dict</span><span class="p">[</span><span class="n">groups</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">group_dict</span><span class="p">[</span><span class="n">groups</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">n_folds</span> <span class="o">&gt;</span> <span class="n">n_groups</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">"Cannot have number of folds=</span><span class="si">{0}</span><span class="s2"> greater than"</span>
                 <span class="s2">" the number of groups=</span><span class="si">{1}</span><span class="s2">"</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_folds</span><span class="p">,</span>
                                                     <span class="n">n_groups</span><span class="p">))</span>

        <span class="n">group_test_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">n_groups</span> <span class="o">//</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">max_test_group_size</span><span class="p">)</span>
        <span class="n">group_test_starts</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_groups</span> <span class="o">-</span> <span class="n">n_splits</span> <span class="o">*</span> <span class="n">group_test_size</span><span class="p">,</span>
                                  <span class="n">n_groups</span><span class="p">,</span> <span class="n">group_test_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">group_test_start</span> <span class="ow">in</span> <span class="n">group_test_starts</span><span class="p">:</span>
            <span class="n">train_array</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">test_array</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="n">group_st</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">group_test_start</span> <span class="o">-</span> <span class="n">group_gap</span> <span class="o">-</span> <span class="n">max_train_group_size</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">train_group_idx</span> <span class="ow">in</span> <span class="n">unique_groups</span><span class="p">[</span><span class="n">group_st</span><span class="p">:(</span><span class="n">group_test_start</span> <span class="o">-</span> <span class="n">group_gap</span><span class="p">)]:</span>
                <span class="n">train_array_tmp</span> <span class="o">=</span> <span class="n">group_dict</span><span class="p">[</span><span class="n">train_group_idx</span><span class="p">]</span>
                
                <span class="n">train_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
                                      <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">train_array</span><span class="p">,</span>
                                                      <span class="n">train_array_tmp</span><span class="p">)),</span>
                                      <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="n">train_end</span> <span class="o">=</span> <span class="n">train_array</span><span class="o">.</span><span class="n">size</span>
 
            <span class="k">for</span> <span class="n">test_group_idx</span> <span class="ow">in</span> <span class="n">unique_groups</span><span class="p">[</span><span class="n">group_test_start</span><span class="p">:</span>
                                                <span class="n">group_test_start</span> <span class="o">+</span>
                                                <span class="n">group_test_size</span><span class="p">]:</span>
                <span class="n">test_array_tmp</span> <span class="o">=</span> <span class="n">group_dict</span><span class="p">[</span><span class="n">test_group_idx</span><span class="p">]</span>
                <span class="n">test_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
                                              <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">test_array</span><span class="p">,</span>
                                                              <span class="n">test_array_tmp</span><span class="p">)),</span>
                                     <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="n">test_array</span>  <span class="o">=</span> <span class="n">test_array</span><span class="p">[</span><span class="n">group_gap</span><span class="p">:]</span>
            
            
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">pass</span>
                    
            <span class="k">yield</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">train_array</span><span class="p">],</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">test_array</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CVTuner</span><span class="p">(</span><span class="n">kt</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">tuner</span><span class="o">.</span><span class="n">Tuner</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">run_trial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trial</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">splits</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">train_indices</span><span class="p">,</span> <span class="n">test_indices</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">:</span>
            <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">],</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">]</span>
            <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">y</span><span class="p">],</span> <span class="p">[</span><span class="n">a</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">y</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            
            <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hypermodel</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">hyperparameters</span><span class="p">)</span>
            <span class="n">hist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span>
                      <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">),</span>
                      <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                      <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
            
            <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">hist</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">hist</span><span class="o">.</span><span class="n">history</span><span class="p">])</span>
        <span class="n">val_losses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">val_losses</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">oracle</span><span class="o">.</span><span class="n">update_trial</span><span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">trial_id</span><span class="p">,</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_losses</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hist</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">keys</span><span class="p">())})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">trial_id</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Model">
<a class="anchor" href="#Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model<a class="anchor-link" href="#Model"> </a>
</h1>
<p>As many people have mentioned, finance datasets are usually have low signal-to-noise ratio (SNR). So, here comes an intuitive question. Does Denoising Auto Encoder (DAE) help in reducing noise and cleaning data in finance datasets?</p>
<p>The idea of using an encoder is the denoise the data. After many attempts at using a unsupervised autoencoder, the choice landed on a bottleneck encoder as this will preserve the intra-feature relations.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-the-autoencoder">
<a class="anchor" href="#Building-the-autoencoder" aria-hidden="true"><span class="octicon octicon-link"></span></a>Building the autoencoder<a class="anchor-link" href="#Building-the-autoencoder"> </a>
</h2>
<p>The autoencoder should aid in denoising the data based on <a href="https://www.semanticscholar.org/paper/Deep-Bottleneck-Classifiers-in-Supervised-Dimension-Parviainen/fb86483f7573f6430fe4597432b0cd3e34b16e43">this</a> paper.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_autoencoder</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">noise</span><span class="o">=.</span><span class="mi">05</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">input_dim</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GaussianNoise</span><span class="p">(</span><span class="n">noise</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">640</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>
    <span class="n">decoded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>
    <span class="n">decoded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'decoded'</span><span class="p">)(</span><span class="n">decoded</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">)(</span><span class="n">decoded</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">,</span>
                              <span class="n">name</span><span class="o">=</span><span class="s1">'label_output'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">encoded</span><span class="p">)</span>

    <span class="n">autoencoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">decoded</span><span class="p">,</span><span class="n">x</span><span class="p">])</span>
    <span class="n">autoencoder</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span>
                        <span class="n">loss</span><span class="o">=</span><span class="p">{</span><span class="s1">'decoded'</span><span class="p">:</span><span class="s1">'mse'</span><span class="p">,</span>
                              <span class="s1">'label_output'</span><span class="p">:</span><span class="s1">'binary_crossentropy'</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">autoencoder</span><span class="p">,</span> <span class="n">encoder</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-the-MLP">
<a class="anchor" href="#Building-the-MLP" aria-hidden="true"><span class="octicon octicon-link"></span></a>Building the MLP<a class="anchor-link" href="#Building-the-MLP"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">hp</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">encoder</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">input_dim</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Concatenate</span><span class="p">()([</span><span class="n">x</span><span class="p">,</span><span class="n">inputs</span><span class="p">])</span> <span class="c1">#use both raw and encoded features</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Float</span><span class="p">(</span><span class="s1">'init_dropout'</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'num_layers'</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">)):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'num_units_</span><span class="si">{i}</span><span class="s1">'</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">256</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">swish</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Float</span><span class="p">(</span><span class="sa">f</span><span class="s1">'dropout_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
                    <span class="n">hp</span><span class="o">.</span><span class="n">Float</span><span class="p">(</span><span class="s1">'lr'</span><span class="p">,</span><span class="mf">0.00001</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="n">default</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)),</span>
                  <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(</span>
                    <span class="n">label_smoothing</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Float</span><span class="p">(</span><span class="s1">'label_smoothing'</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)),</span>
                  <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">AUC</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s1">'auc'</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Defining-and-training-the-autoencoder">
<a class="anchor" href="#Defining-and-training-the-autoencoder" aria-hidden="true"><span class="octicon octicon-link"></span></a>Defining and training the autoencoder<a class="anchor-link" href="#Defining-and-training-the-autoencoder"> </a>
</h2>
<p>We add gaussian noise with mean and std from training datea. After training we lock the layersfin the encoder from further training.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">autoencoder</span><span class="p">,</span> <span class="n">encoder</span> <span class="o">=</span> <span class="n">build_autoencoder</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> 
                                         <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                         <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">autoencoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span>
                <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> 
                <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
                        <span class="s1">'val_loss'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                        <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/1000
346/346 [==============================] - 7s 12ms/step - loss: 2.1184 - decoded_loss: 1.3832 - label_output_loss: 0.7352 - val_loss: 0.8046 - val_decoded_loss: 0.1152 - val_label_output_loss: 0.6894
Epoch 2/1000
346/346 [==============================] - 3s 10ms/step - loss: 1.0088 - decoded_loss: 0.3173 - label_output_loss: 0.6915 - val_loss: 0.7703 - val_decoded_loss: 0.0810 - val_label_output_loss: 0.6893
Epoch 3/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9952 - decoded_loss: 0.3053 - label_output_loss: 0.6899 - val_loss: 0.7617 - val_decoded_loss: 0.0728 - val_label_output_loss: 0.6890
Epoch 4/1000
346/346 [==============================] - 3s 9ms/step - loss: 0.9690 - decoded_loss: 0.2794 - label_output_loss: 0.6895 - val_loss: 0.7576 - val_decoded_loss: 0.0686 - val_label_output_loss: 0.6890
Epoch 5/1000
346/346 [==============================] - 3s 9ms/step - loss: 0.9750 - decoded_loss: 0.2856 - label_output_loss: 0.6894 - val_loss: 0.7562 - val_decoded_loss: 0.0676 - val_label_output_loss: 0.6886
Epoch 6/1000
346/346 [==============================] - 3s 9ms/step - loss: 0.9759 - decoded_loss: 0.2867 - label_output_loss: 0.6892 - val_loss: 0.7537 - val_decoded_loss: 0.0645 - val_label_output_loss: 0.6892
Epoch 7/1000
346/346 [==============================] - 4s 10ms/step - loss: 0.9767 - decoded_loss: 0.2876 - label_output_loss: 0.6891 - val_loss: 0.7552 - val_decoded_loss: 0.0666 - val_label_output_loss: 0.6886
Epoch 8/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9884 - decoded_loss: 0.2994 - label_output_loss: 0.6889 - val_loss: 0.7473 - val_decoded_loss: 0.0590 - val_label_output_loss: 0.6882
Epoch 9/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9531 - decoded_loss: 0.2644 - label_output_loss: 0.6887 - val_loss: 0.7472 - val_decoded_loss: 0.0592 - val_label_output_loss: 0.6880
Epoch 10/1000
346/346 [==============================] - 3s 10ms/step - loss: 1.0210 - decoded_loss: 0.3324 - label_output_loss: 0.6886 - val_loss: 0.7472 - val_decoded_loss: 0.0586 - val_label_output_loss: 0.6887
Epoch 11/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9625 - decoded_loss: 0.2740 - label_output_loss: 0.6885 - val_loss: 0.7477 - val_decoded_loss: 0.0595 - val_label_output_loss: 0.6883
Epoch 12/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9719 - decoded_loss: 0.2835 - label_output_loss: 0.6884 - val_loss: 0.7530 - val_decoded_loss: 0.0650 - val_label_output_loss: 0.6879
Epoch 13/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9867 - decoded_loss: 0.2983 - label_output_loss: 0.6884 - val_loss: 0.7494 - val_decoded_loss: 0.0611 - val_label_output_loss: 0.6882
Epoch 14/1000
346/346 [==============================] - 3s 9ms/step - loss: 0.9518 - decoded_loss: 0.2636 - label_output_loss: 0.6881 - val_loss: 0.7477 - val_decoded_loss: 0.0590 - val_label_output_loss: 0.6887
Epoch 15/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9466 - decoded_loss: 0.2585 - label_output_loss: 0.6881 - val_loss: 0.7474 - val_decoded_loss: 0.0595 - val_label_output_loss: 0.6879
Epoch 16/1000
346/346 [==============================] - 3s 9ms/step - loss: 0.9588 - decoded_loss: 0.2708 - label_output_loss: 0.6880 - val_loss: 0.7467 - val_decoded_loss: 0.0585 - val_label_output_loss: 0.6882
Epoch 17/1000
346/346 [==============================] - 3s 10ms/step - loss: 1.0079 - decoded_loss: 0.3200 - label_output_loss: 0.6879 - val_loss: 0.7465 - val_decoded_loss: 0.0584 - val_label_output_loss: 0.6881
Epoch 18/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9491 - decoded_loss: 0.2614 - label_output_loss: 0.6877 - val_loss: 0.7464 - val_decoded_loss: 0.0584 - val_label_output_loss: 0.6881
Epoch 19/1000
346/346 [==============================] - 3s 9ms/step - loss: 0.9493 - decoded_loss: 0.2616 - label_output_loss: 0.6877 - val_loss: 0.7551 - val_decoded_loss: 0.0671 - val_label_output_loss: 0.6881
Epoch 20/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9348 - decoded_loss: 0.2472 - label_output_loss: 0.6876 - val_loss: 0.7574 - val_decoded_loss: 0.0693 - val_label_output_loss: 0.6881
Epoch 21/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9351 - decoded_loss: 0.2474 - label_output_loss: 0.6877 - val_loss: 0.7526 - val_decoded_loss: 0.0644 - val_label_output_loss: 0.6882
Epoch 22/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9658 - decoded_loss: 0.2783 - label_output_loss: 0.6874 - val_loss: 0.7521 - val_decoded_loss: 0.0640 - val_label_output_loss: 0.6881
Epoch 23/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9430 - decoded_loss: 0.2556 - label_output_loss: 0.6874 - val_loss: 0.7504 - val_decoded_loss: 0.0620 - val_label_output_loss: 0.6884
Epoch 24/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9473 - decoded_loss: 0.2602 - label_output_loss: 0.6871 - val_loss: 0.7534 - val_decoded_loss: 0.0653 - val_label_output_loss: 0.6881
Epoch 25/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9362 - decoded_loss: 0.2489 - label_output_loss: 0.6873 - val_loss: 0.7517 - val_decoded_loss: 0.0635 - val_label_output_loss: 0.6882
Epoch 26/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9463 - decoded_loss: 0.2592 - label_output_loss: 0.6872 - val_loss: 0.7538 - val_decoded_loss: 0.0654 - val_label_output_loss: 0.6883
Epoch 27/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9584 - decoded_loss: 0.2712 - label_output_loss: 0.6872 - val_loss: 0.7582 - val_decoded_loss: 0.0699 - val_label_output_loss: 0.6883
Epoch 28/1000
346/346 [==============================] - 3s 10ms/step - loss: 0.9484 - decoded_loss: 0.2614 - label_output_loss: 0.6870 - val_loss: 0.7580 - val_decoded_loss: 0.0699 - val_label_output_loss: 0.6881
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x7fa49aa04fd0&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">encoder</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s1">'encoder.hdf5'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">encoder</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">'encoder.hdf5'</span><span class="p">)</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Running-CV">
<a class="anchor" href="#Running-CV" aria-hidden="true"><span class="octicon octicon-link"></span></a>Running CV<a class="anchor-link" href="#Running-CV"> </a>
</h2>
<p>Following <a href="https://www.kaggle.com/gogo827jz/jane-street-ffill-xgboost-purgedtimeseriescv">this notebook</a> which use 5 <code>PurgedGroupTimeSeriesSplit</code> split on the dates in the training data.</p>
<p>We add the locked encoder as the first layer of the MLP. This seems to help in speeding up the submission rather than first predicting using the encoder then using the MLP.</p>
<p>We use a Baysian Optimizer to find the optimal HPs for out model. 20 trials take about 2 hours on GPU.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">hp</span><span class="p">:</span> <span class="n">build_model</span><span class="p">(</span>
    <span class="n">hp</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">encoder</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">CVTuner</span><span class="p">(</span>
    <span class="n">hypermodel</span> <span class="o">=</span> <span class="n">model_fn</span><span class="p">,</span>
    <span class="n">oracle</span><span class="o">=</span><span class="n">kt</span><span class="o">.</span><span class="n">oracles</span><span class="o">.</span><span class="n">BayesianOptimization</span><span class="p">(</span>
        <span class="n">objective</span><span class="o">=</span><span class="n">kt</span><span class="o">.</span><span class="n">Objective</span><span class="p">(</span><span class="s1">'val_auc'</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s1">'max'</span><span class="p">),</span>
        <span class="n">num_initial_points</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">max_trials</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gkf</span> <span class="o">=</span> <span class="n">PurgedGroupTimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">group_gap</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">splits</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">gkf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">'date'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">search</span><span class="p">((</span><span class="n">x_train</span><span class="p">,),(</span><span class="n">y_train</span><span class="p">,),</span>
             <span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span>
             <span class="n">batch_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
             <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
             <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
                    <span class="s1">'val_auc'</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'max'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hp</span>  <span class="o">=</span> <span class="n">tuner</span><span class="o">.</span><span class="n">get_best_hyperparameters</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">hp</span><span class="p">,</span><span class="sa">f</span><span class="s1">'./best_hp_</span><span class="si">{</span><span class="n">SEED</span><span class="si">}</span><span class="s1">.pkl'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">fold</span><span class="p">,</span> <span class="p">(</span><span class="n">train_indices</span><span class="p">,</span> <span class="n">test_indices</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">splits</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model_fn</span><span class="p">(</span><span class="n">hp</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">),</span><span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="s1">'val_auc'</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s1">'max'</span><span class="p">,</span><span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="sa">f</span><span class="s1">'./model_</span><span class="si">{</span><span class="n">SEED</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s1">.hdf5'</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'lr'</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span><span class="p">),</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="sa">f</span><span class="s1">'./model_</span><span class="si">{</span><span class="n">SEED</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s1">_finetune.hdf5'</span><span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">results_summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

</div>



  </div><a class="u-url" href="/blog/time%20series/stock/kaggle/2021/01/15/jane-street-market-prediction.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Thoughts when I am building</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/austinyhc" title="austinyhc"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/austinyht" title="austinyht"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
