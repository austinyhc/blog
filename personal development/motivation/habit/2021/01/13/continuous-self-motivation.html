<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Continuous Self Motivation | AUSTIN CAN HELP</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Continuous Self Motivation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="1% Better Everyday" />
<meta property="og:description" content="1% Better Everyday" />
<link rel="canonical" href="https://austinyhc.github.io/blog/personal%20development/motivation/habit/2021/01/13/continuous-self-motivation.html" />
<meta property="og:url" content="https://austinyhc.github.io/blog/personal%20development/motivation/habit/2021/01/13/continuous-self-motivation.html" />
<meta property="og:site_name" content="AUSTIN CAN HELP" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-13T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://austinyhc.github.io/blog/personal%20development/motivation/habit/2021/01/13/continuous-self-motivation.html","@type":"BlogPosting","headline":"Continuous Self Motivation","dateModified":"2021-01-13T00:00:00-06:00","datePublished":"2021-01-13T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://austinyhc.github.io/blog/personal%20development/motivation/habit/2021/01/13/continuous-self-motivation.html"},"description":"1% Better Everyday","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://austinyhc.github.io/blog/feed.xml" title="AUSTIN CAN HELP" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">AUSTIN CAN HELP</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Continuous Self Motivation</h1><p class="page-description">1% Better Everyday</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-01-13T00:00:00-06:00" itemprop="datePublished">
        Jan 13, 2021
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#personal development">personal development</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#motivation">motivation</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#habit">habit</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/austinyhc/blog/tree/master/_notebooks/continuous-self-motivation.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/austinyhc/blog/blob/master/_notebooks/continuous-self-motivation.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#The-Four-Big-Ideas">The Four Big Ideas </a></li>
<li class="toc-entry toc-h1"><a href="#I.-Customize-1cycle">I. Customize 1cycle </a></li>
<li class="toc-entry toc-h1"><a href="#II.-EfficientNet">II. EfficientNet </a>
<ul>
<li class="toc-entry toc-h2"><a href="#B0-to-B7-variats-of-EfficientNet">B0 to B7 variats of EfficientNet </a></li>
<li class="toc-entry toc-h2"><a href="#Keras-implementation-of-EfficientNet">Keras implementation of EfficientNet </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Clarification">Clarification </a>
<ul>
<li class="toc-entry toc-h2"><a href="#AutoAugment">AutoAugment </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/continuous-self-motivation.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Four-Big-Ideas">
<a class="anchor" href="#The-Four-Big-Ideas" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Four Big Ideas<a class="anchor-link" href="#The-Four-Big-Ideas"> </a>
</h2>
<ol>
<li>Habits are the compound interest of self-improvement.</li>
<li>If you want better results, then forget about setting goals. Focus on your system instead.</li>
<li>The most effective way to change your habits is to focus not on what you want to achieve, but on who you wish to become.</li>
<li>The Four Laws of Behavior Change are a simple set of rules we can use to build better habits. They are <ul>
<li>make it obvious</li>
<li>make it attractive</li>
<li>make it easy</li>
<li>make it satisfying.</li>
</ul>
</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://jamesclear.com/wp-content/uploads/2015/08/tiny-gains-graph.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="I.-Customize-1cycle">
<a class="anchor" href="#I.-Customize-1cycle" aria-hidden="true"><span class="octicon octicon-link"></span></a>I. Customize 1cycle<a class="anchor-link" href="#I.-Customize-1cycle"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This learning rate scheduler allows us to easily train a network using Leslie Smith's 1cycle policy. To learn more about the 1cycle technique for training neural networks check out <a href="https://arxiv.org/pdf/1803.09820.pdf">Leslie Smith's paper</a> and for more graphical and intuitive explanation checkout out <a href="https://sgugger.github.io/the-1cycle-policy.html">Sylvain Gugger's post</a>.</p>
<p>To use 1cycle policy we will need an <a href="https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html">optimum learning rate</a>. We can find this learning rate by using a learning finder which can be called by using <code>lr_finder</code> as <code>fastai</code> does. It will do a mock training by going over a large range of learning rates, then plot them against the losses. We will then pick a value a bit before the minimum, where the loss still improves. Our graph would something like this:</p>
<p><img src="https://fastai1.fast.ai/imgs/onecycle_finder.png" alt=""></p>
<p>There is somthing to add, if we are transfer learning, we do not want to start off with too large a learning rate, or we will erase the intelligence of the model already contained in its weights. Instead, we begin with a very small learning rate and increase it gradually before lowering it again to fine-tune the weights.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>After digging into the rabbit hole, I found there are two different learning rate schedule utility in tensorflow, the naming is very confusing, <a href="https://github.com/tensorflow/tensorflow/blob/582c8d236cb079023657287c318ff26adb239002/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py#L34-L61">keras.optimizers.schedules.LearningRateSchedule</a> and <a href="https://github.com/tensorflow/tensorflow/blob/582c8d236cb079023657287c318ff26adb239002/tensorflow/python/keras/callbacks.py#L1858-L1920">keras.callbacks.LearningRateScheduler</a>. Although the naming is very similar, they are different in some senses.

</div>- The former is subclassing from <code>tf.keras.optimizers</code> while the latter is from <code>tf.keras.Callback</code>
<ul>
<li>The former schedule the learning rate per iteration while the former is per epoch.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="II.-EfficientNet">
<a class="anchor" href="#II.-EfficientNet" aria-hidden="true"><span class="octicon octicon-link"></span></a>II. EfficientNet<a class="anchor-link" href="#II.-EfficientNet"> </a>
</h1>
<p><strong>(Read the EfficientNet paper and summarize in one of the section of this notebook)</strong></p>
<p>EfficientNet, first introduced in <a href="https://arxiv.org/abs/1905.11946">Tan and Le, 2019</a> is among the most efficient models (i.e. requiring least FLOPS for inference) that reaches state-of-the-art accracy on both imagenet and common image classification transfer learning tasks.</p>
<p>The smallest base model is similar to <a href="https://arxiv.org/abs/1807.11626">MnasNet</a>, which reached near-SOTA with a significantly smaller model. By introducing a heuristic way to scale the model, EfficientNet provides a family of models (B0 to B7) that represents a good combination of efficiency and accuracy on a variety of scales. Such a scaling heuristics (<strong>compound-scaling</strong>, details see <a href="https://arxiv.org/abs/1905.11946">Tan and Le, 2019</a>) allows the efficiency-oriented base model (B0) to surpass models at every scale, while avoiding extensive grid-search of hyperparameters.</p>
<p>A summary of the latest updates on the model is available at <a href="">here</a>, where various augmentation schemes and semi-supervised learning approaches are applied to further improve the imagenet performance of the models. These extensions of the model can be used by updating weights without changing model topology</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="B0-to-B7-variats-of-EfficientNet">
<a class="anchor" href="#B0-to-B7-variats-of-EfficientNet" aria-hidden="true"><span class="octicon octicon-link"></span></a>B0 to B7 variats of EfficientNet<a class="anchor-link" href="#B0-to-B7-variats-of-EfficientNet"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Keras-implementation-of-EfficientNet">
<a class="anchor" href="#Keras-implementation-of-EfficientNet" aria-hidden="true"><span class="octicon octicon-link"></span></a>Keras implementation of EfficientNet<a class="anchor-link" href="#Keras-implementation-of-EfficientNet"> </a>
</h2>
<p>An implementation of EfficientNet B0 to B7 has been shipped with <code>tf.keras</code> since TF2.3. To use EfficientNetB0 for classifying 1000 classes of images from imagenet, run:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.applications</span> <span class="kn">import</span> <span class="n">EfficientNetB0</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">EfficientNetB0</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">'imagenet'</span><span class="p">)</span>
</pre></div>
<p>The B0 model takes input images of shape (224,224,3), and the input data should range [0,255]. <strong><em>Normailzation is included as part of the model.</em></strong></p>
<p>Because training EfficientNet on imagenet takes a tremendous amount of resources and several techniques that are not a part of the model architecture itself. Hence the Keras implementations by default loads pre-trained weights obtained via training with <a href="https://arxiv.org/abs/1805.09501">AutoAugment</a>.</p>
<p>From B0 to B7 base model, the input shapes are different. Here is a list of input shpae expected for each model:</p>
<table>
<thead>
<tr>
<th>Base model</th>
<th>resolution</th>
</tr>
</thead>
<tbody>
<tr>
<td>EfficientNetB0</td>
<td>224</td>
</tr>
<tr>
<td>EfficientNetB1</td>
<td>240</td>
</tr>
<tr>
<td>EfficientNetB2</td>
<td>260</td>
</tr>
<tr>
<td>EfficientNetB3</td>
<td>300</td>
</tr>
<tr>
<td>EfficientNetB4</td>
<td>380</td>
</tr>
<tr>
<td>EfficientNetB5</td>
<td>456</td>
</tr>
<tr>
<td>EfficientNetB6</td>
<td>528</td>
</tr>
<tr>
<td>EfficientNetB7</td>
<td>600</td>
</tr>
</tbody>
</table>
<p>When the model is intended for transfer learning, the Keras implementation provides a option to remove the top layers:</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">EfficientNetB0</span><span class="p">(</span><span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'imagenet'</span><span class="p">)</span>
</pre></div>
<p>This option excludes the final Dense layer that turns 1280 features on the penultimate layer into prediction of the 1000 ImageNet classes. Replacing the top layer with custom layers allows using EfficientNet as a feature extractor in a transfer learning workflow.</p>
<p>Another argument in the model constructor worth noticing is drop_connect_rate which controls the dropout rate responsible for stochastic depth. This parameter serves as a toggle for extra regularization in finetuning, but does not affect loaded weights. For example, when stronger regularization is desired, try:</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">EfficientNetB0</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">'imagenet'</span><span class="p">,</span> <span class="n">drop_connect_rate</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
</pre></div>
<p>The default value for <code>drop_connect_rate</code> is 0.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Clarification">
<a class="anchor" href="#Clarification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Clarification<a class="anchor-link" href="#Clarification"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="AutoAugment">
<a class="anchor" href="#AutoAugment" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="https://arxiv.org/abs/1805.09501">AutoAugment</a><a class="anchor-link" href="#AutoAugment"> </a>
</h2>
<p>In this <a href="https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/">article</a>, in section <code>Keras implementation of EfficientNet</code>, it says</p>
<blockquote>
<p>Because training EfficientNet on ImageNet takes a tremendous amount of resources and several techniques that are not a part of the model architecture itself. Hence the Keras implementation by default loads pre-trained weights obtained via training with AutoAugment</p>
</blockquote>
<p>It means the weights of keras EfficientNet are trained on the pre-trained from AutoAugment. My follow-up question is what dataset does the AutoAugment trained on?</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/blog/personal%20development/motivation/habit/2021/01/13/continuous-self-motivation.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Thoughts when I am building</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/austinyhc" title="austinyhc"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/austinyht" title="austinyht"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
